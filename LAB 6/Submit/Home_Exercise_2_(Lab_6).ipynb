{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "Hdfq_PH9MIMH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "dx5Rj9WMFpax"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvlvMFtzFpaw"
      },
      "source": [
        "## Data Downloading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "hpFeBV5IFpay"
      },
      "outputs": [],
      "source": [
        "zip_path = \"/content/titanic.zip\"\n",
        "extract_to = \"data/\"\n",
        "# open the zip file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    # extract specific files\n",
        "    zip_ref.extract(\"train.csv\", extract_to)\n",
        "    zip_ref.extract(\"test.csv\", extract_to)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "csCdhSyTFpay"
      },
      "outputs": [],
      "source": [
        "# take the train data and test data\n",
        "train_data = pd.read_csv(\"data/train.csv\")\n",
        "test_data = pd.read_csv(\"data/test.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlcqP76GFpay"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(train, test):\n",
        "    # extract title using regex for robustness\n",
        "    train['Title'] = train['Name'].str.extract(r',\\s*([^\\.]+)\\.')[0]\n",
        "    test['Title'] = test['Name'].str.extract(r',\\s*([^\\.]+)\\.')[0]\n",
        "\n",
        "    title_list = ['Mr', 'Miss', 'Master', 'Mrs']\n",
        "\n",
        "    # replace uncommon titles with 'Misc'\n",
        "    train['Title'] = train['Title'].apply(lambda x: x if x in title_list else 'Misc')\n",
        "    test['Title'] = test['Title'].apply(lambda x: x if x in title_list else 'Misc')\n",
        "\n",
        "    # drop unnecessary columns\n",
        "    drop_cols = ['PassengerId', 'Ticket', 'Name', 'SibSp', 'Parch', 'Cabin']\n",
        "    train.drop(columns=drop_cols, inplace=True, errors='ignore')\n",
        "    test.drop(columns=drop_cols, inplace=True, errors='ignore')\n",
        "\n",
        "    # encode categorical variables to 0 and 1 for \"Sex\" column and \"Embarked\" column\n",
        "    train[\"Sex\"] = train[\"Sex\"].map({\"male\": 0, \"female\": 1})\n",
        "    test[\"Sex\"] = test[\"Sex\"].map({\"male\": 0, \"female\": 1})\n",
        "\n",
        "    train[\"Embarked\"] = train[\"Embarked\"].fillna(train[\"Embarked\"].mode()[0])\n",
        "    test[\"Embarked\"] = test[\"Embarked\"].fillna(train[\"Embarked\"].mode()[0])\n",
        "\n",
        "    # fill missing Fare values using train median\n",
        "    train['Fare'] = train['Fare'].fillna(train['Fare'].median())\n",
        "    test['Fare'] = test['Fare'].fillna(train['Fare'].median())  # Using train's median for consistency\n",
        "\n",
        "    # fill missing Age values based on Title median from training set\n",
        "    title_age_median = train.groupby('Title')['Age'].median()\n",
        "    train['Age'] = train.apply(lambda row: title_age_median[row['Title']] if pd.isna(row['Age']) else row['Age'], axis=1)\n",
        "    test['Age'] = test.apply(lambda row: title_age_median[row['Title']] if pd.isna(row['Age']) else row['Age'], axis=1)  # Using train's median\n",
        "\n",
        "    return train, test\n"
      ],
      "metadata": {
        "id": "ytRo4LqPJmSd"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Implementation\n",
        "#### Using sigmoid and gradient descent"
      ],
      "metadata": {
        "id": "4__l0DkJNDzZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sigmoid activation function\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "# train logistic regression using gradient descent\n",
        "def fit(X, y, learning_rate=0.01, epochs=20000):\n",
        "    # convert input data to NumPy arrays and ensure they are of float type\n",
        "    X = np.array(X).astype(float)\n",
        "    y = np.array(y).astype(float)\n",
        "\n",
        "    # get the number of samples (m) and features (n)\n",
        "    m, n = X.shape\n",
        "    # initial weights and bias with zero\n",
        "    weights = np.zeros(n)\n",
        "    bias = 0\n",
        "\n",
        "    # perform gradient descent for 'epochs' iterations\n",
        "    for _ in range(epochs):\n",
        "        linear_model = np.dot(X, weights) + bias\n",
        "        predictions = sigmoid(linear_model)\n",
        "\n",
        "        # compute gradients\n",
        "        dw = (1 / m) * np.dot(X.T, (predictions - y)) # derivative weights\n",
        "        db = (1 / m) * np.sum(predictions - y)  # derivative bias\n",
        "\n",
        "        # update parameters\n",
        "        weights -= learning_rate * dw\n",
        "        bias -= learning_rate * db\n",
        "\n",
        "    return weights, bias\n",
        "\n",
        "# make predictions using the trained logistic regression model\n",
        "def predict(X, weights, bias):\n",
        "    # convert input data to NumPy array and ensure it's float type\n",
        "    X = np.array(X).astype(float)\n",
        "    # compute the linear combination of inputs and trained weights\n",
        "    linear_model = np.dot(X, weights) + bias\n",
        "    # apply sigmoid activation to get probability predictions\n",
        "    predictions = sigmoid(linear_model)\n",
        "    # convert probabilities to binary class labels (0 or 1) with threshold 0.5\n",
        "    return (predictions >= 0.5).astype(int)\n"
      ],
      "metadata": {
        "id": "eUnh_9tIJ7k8"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# call function preprocess data\n",
        "train_processed, test_processed = preprocess_data(train_data, test_data)\n",
        "\n",
        "# apply log transformation to numeric columns\n",
        "numeric_cols = ['Age', 'Fare']\n",
        "train_processed[numeric_cols] = np.log1p(train_processed[numeric_cols])\n",
        "test_processed[numeric_cols] = np.log1p(test_processed[numeric_cols])\n",
        "\n",
        "# using one-hot encoding categorical variables\n",
        "train_processed = pd.get_dummies(train_processed).astype(float)\n",
        "test_processed = pd.get_dummies(test_processed).astype(float)\n",
        "\n",
        "# separate features and target variable\n",
        "X_train = train_processed.drop(columns=['Survived'])\n",
        "y_train = train_processed['Survived']\n",
        "\n",
        "# align train and test sets to have the same features\n",
        "X_train, X_test = X_train.align(test_processed, join='left', axis=1, fill_value=0)\n",
        "\n",
        "# convert to NumPy arrays\n",
        "X_train = X_train.values\n",
        "y_train = y_train.values\n",
        "X_test = X_test.values"
      ],
      "metadata": {
        "id": "8qsflg6RKT8M"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Process"
      ],
      "metadata": {
        "id": "uwEQwHTWOpWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train logistic regression model\n",
        "weights, bias = fit(X_train, y_train, epochs=800000)\n",
        "\n",
        "# make predictions\n",
        "y_pred = predict(X_test, weights, bias)\n"
      ],
      "metadata": {
        "id": "ItuFWiWwOxLN"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export CSV file"
      ],
      "metadata": {
        "id": "HM9_0uA9OVvC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a DataFrame for submission\n",
        "submission = pd.DataFrame({\n",
        "    'PassengerId': test_data.index + 892, # PassengerId index\n",
        "    'Survived': y_pred  # predictions\n",
        "})\n",
        "# extract csv file\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "print(\"Submission file created!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ForAZDGKKW22",
        "outputId": "214fb04c-912c-4735-e46f-47048b5f4b88"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file created!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KAGGLE SUBMISSION\n",
        "#### Link submission: https://drive.google.com/file/d/1BX7FpIXofd55rRdFm2bUyLGIg2RO35yK/view?usp=sharing"
      ],
      "metadata": {
        "id": "KWgRvDf6OhJr"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}