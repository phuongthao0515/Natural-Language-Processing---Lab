{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11243419,"sourceType":"datasetVersion","datasetId":7024930}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import Libraries","metadata":{"id":"mswUN254nohl"}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nimport pandas as pd\nimport numpy as np\nimport zipfile\nimport re\nimport string\nimport nltk\nimport torch\nfrom nltk.corpus import stopwords\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, SimpleRNN, Dense, GlobalAveragePooling1D,GRU,LSTM,Bidirectional,Dropout,BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n","metadata":{"id":"65tF4OMEnnBv","trusted":true,"execution":{"iopub.status.busy":"2025-04-02T08:57:29.500209Z","iopub.execute_input":"2025-04-02T08:57:29.500515Z","iopub.status.idle":"2025-04-02T08:57:29.506323Z","shell.execute_reply.started":"2025-04-02T08:57:29.500487Z","shell.execute_reply":"2025-04-02T08:57:29.505097Z"}},"outputs":[],"execution_count":43},{"cell_type":"markdown","source":"## Data Downloading","metadata":{"id":"DrN5IrI5nrFS"}},{"cell_type":"code","source":"# zip_path = \"/content/IMDB Dataset.csv.zip\"\n# extract_to = \"data/\"\n# # Open the zip file\n# with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n#     # Extract specific files\n#     zip_ref.extract(\"IMDB Dataset.csv\", extract_to)","metadata":{"id":"rpEVfrAhozR3","trusted":true,"execution":{"iopub.status.busy":"2025-04-02T08:57:29.507599Z","iopub.execute_input":"2025-04-02T08:57:29.507991Z","iopub.status.idle":"2025-04-02T08:57:29.523273Z","shell.execute_reply.started":"2025-04-02T08:57:29.507965Z","shell.execute_reply":"2025-04-02T08:57:29.522313Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/imdb-dataset/IMDB Dataset.csv\")\ntrain_df, test_df = train_test_split(train_data, test_size=0.1, random_state=42)","metadata":{"id":"2akOz-h2qt2W","trusted":true,"execution":{"iopub.status.busy":"2025-04-02T08:57:29.525417Z","iopub.execute_input":"2025-04-02T08:57:29.525684Z","iopub.status.idle":"2025-04-02T08:57:30.218468Z","shell.execute_reply.started":"2025-04-02T08:57:29.525661Z","shell.execute_reply":"2025-04-02T08:57:30.217616Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"# Tải stopwords nếu chưa có\nnltk.download(\"stopwords\")\n\n# Khai báo stopwords\nstop_words = set(stopwords.words(\"english\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T08:57:30.220959Z","iopub.execute_input":"2025-04-02T08:57:30.221220Z","iopub.status.idle":"2025-04-02T08:57:30.227455Z","shell.execute_reply.started":"2025-04-02T08:57:30.221199Z","shell.execute_reply":"2025-04-02T08:57:30.226578Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"}],"execution_count":46},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{"id":"WGxSHk_bnxvq"}},{"cell_type":"code","source":"def preprocess_text(text):\n    text = text.lower()  # Chuyển thành chữ thường\n    text = re.sub(r\"\\d+\", \"\", text)  # Xóa số\n    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))  # Xóa dấu câu\n    text = \" \".join([word for word in text.split() if word not in stop_words])  # Xóa stopwords\n    text = re.sub(r\"\\s+\", \" \", text).strip()  # Xóa khoảng trắng dư thừa\n    return text\n\n# ✅ ÁP DỤNG TIỀN XỬ LÝ CHO DỮ LIỆU\ntrain_df[\"review\"] = train_df[\"review\"].apply(preprocess_text)\ntest_df[\"review\"] = test_df[\"review\"].apply(preprocess_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T08:57:30.228552Z","iopub.execute_input":"2025-04-02T08:57:30.228937Z","iopub.status.idle":"2025-04-02T08:57:31.244544Z","shell.execute_reply.started":"2025-04-02T08:57:30.228898Z","shell.execute_reply":"2025-04-02T08:57:31.242572Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-47-d389b554f952>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# ✅ ÁP DỤNG TIỀN XỬ LÝ CHO DỮ LIỆU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"review\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"review\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"review\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"review\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4922\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4923\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4924\u001b[0;31m         ).apply()\n\u001b[0m\u001b[1;32m   4925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4926\u001b[0m     def _reindex_indexer(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1426\u001b[0m         \u001b[0;31m# self.func is Callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1427\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1505\u001b[0m         \u001b[0;31m#  Categorical (GH51645).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1506\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCategoricalDtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1507\u001b[0;31m         mapped = obj._map_values(\n\u001b[0m\u001b[1;32m   1508\u001b[0m             \u001b[0mmapper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurried\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1509\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1742\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mna_action\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1743\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1744\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m         return lib.map_infer_mask(\n","\u001b[0;32mlib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n","\u001b[0;32m<ipython-input-47-d389b554f952>\u001b[0m in \u001b[0;36mpreprocess_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"\\d+\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Xóa số\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaketrans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Xóa dấu câu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Xóa stopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"\\s+\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Xóa khoảng trắng dư thừa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":47},{"cell_type":"code","source":"# Tách cột review và sentiment\nX_train = train_df[\"review\"].values\ny_train = train_df[\"sentiment\"].values\nX_test = test_df[\"review\"].values\ny_test = test_df[\"sentiment\"].values\n\n# Kiểm tra kiểu dữ liệu của nhãn\nprint(\"y_train type:\", type(y_train))\nprint(\"Unique values in y_train:\", np.unique(y_train))\n\n# Nếu nhãn là chuỗi, chuyển thành số (1 cho 'positive', 0 cho 'negative')\nif y_train.dtype == 'O':  # 'O' (object) có thể chứa chuỗi\n    label_mapping = {'positive': 1, 'negative': 0}\n    y_train = np.array([label_mapping[label] for label in y_train], dtype=np.float32)\n    y_test = np.array([label_mapping[label] for label in y_test], dtype=np.float32)\nelse:\n    y_train = y_train.astype(np.float32)\n    y_test = y_test.astype(np.float32)\n\n# Số lượng từ tối đa trong vocab\nMAX_WORDS = 10000\n# Độ dài tối đa của mỗi review\nMAX_LEN = 500\n\nEMBEDDING_DIMS = 128\n\n# Tokenize dữ liệu văn bản\ntokenizer = Tokenizer(num_words=MAX_WORDS, oov_token=\"<OOV>\")\ntokenizer.fit_on_texts(X_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T08:57:31.245138Z","iopub.status.idle":"2025-04-02T08:57:31.245454Z","shell.execute_reply":"2025-04-02T08:57:31.245331Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Build Model","metadata":{"id":"uiguYT6Lnzo-"}},{"cell_type":"markdown","source":"#### Vanilla RNN Model","metadata":{"id":"BpsGImh3KVeP"}},{"cell_type":"code","source":"# Vanilla RNN model\ndef create_rnn_model():\n    model = Sequential([\n        Embedding(input_dim=MAX_WORDS, output_dim=EMBEDDING_DIMS, mask_zero=True),  # mask_zero=True \n        SimpleRNN(128, dropout=0.2, recurrent_dropout=0.2, return_sequences=False),  # return_sequences=False -> output 2D\n        Dense(1, activation='sigmoid')\n    ])\n    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n    return model","metadata":{"id":"kJ3_ExCopnMR","trusted":true,"execution":{"iopub.status.busy":"2025-04-02T09:19:44.325706Z","iopub.execute_input":"2025-04-02T09:19:44.326133Z","iopub.status.idle":"2025-04-02T09:19:44.331623Z","shell.execute_reply.started":"2025-04-02T09:19:44.326095Z","shell.execute_reply":"2025-04-02T09:19:44.330385Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)","metadata":{"id":"WfIbHpM1o4x1","trusted":true,"execution":{"iopub.status.busy":"2025-04-02T08:57:31.247268Z","iopub.status.idle":"2025-04-02T08:57:31.247678Z","shell.execute_reply":"2025-04-02T08:57:31.247505Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### GRU Model","metadata":{"id":"peN4Yxi5KYRp"}},{"cell_type":"code","source":"# GRU model\n# def create_gru_model():\n#     model = Sequential()\n#     model.add(Embedding(input_dim=MAX_WORDS, output_dim=EMBEDDING_DIMS, input_length=MAX_LEN))  # Embedding layer\n#     model.add(GRU(128, dropout=0.2, recurrent_dropout=0.2))  # GRU layer (no return_sequences)\n#     model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n\n#     model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n#     return model\nfrom tensorflow.keras.layers import GRU, Dense, Dropout, Embedding, BatchNormalization, Bidirectional\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.models import Sequential\n\ndef create_gru_model():\n    model = Sequential([\n        # Embedding Layer\n        Embedding(input_dim=MAX_WORDS, output_dim=EMBEDDING_DIMS, input_length=MAX_LEN),\n        \n        # First GRU Layer (returns sequences for stacking)\n        Bidirectional(GRU(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.1)),\n        BatchNormalization(),\n\n        # Second GRU Layer\n        Bidirectional(GRU(32, dropout=0.1, recurrent_dropout=0.05)),\n        Dropout(0.2),\n\n        # Fully Connected Layers\n        Dense(16, activation=\"relu\", kernel_regularizer=l2(0.001)),\n        BatchNormalization(),\n        \n        # Output Layer\n        Dense(1, activation=\"sigmoid\")\n    ])\n\n    model.compile(\n        loss='binary_crossentropy',\n        optimizer=Adam(learning_rate=1e-3),\n        metrics=['accuracy']\n    )\n    return model\n\n","metadata":{"id":"fCO7MXDuKGat","trusted":true,"execution":{"iopub.status.busy":"2025-04-02T09:26:14.362132Z","iopub.execute_input":"2025-04-02T09:26:14.362434Z","iopub.status.idle":"2025-04-02T09:26:14.368482Z","shell.execute_reply.started":"2025-04-02T09:26:14.362411Z","shell.execute_reply":"2025-04-02T09:26:14.367560Z"}},"outputs":[],"execution_count":62},{"cell_type":"markdown","source":"#### LSTM Model","metadata":{"id":"AdcnRn5SpAYr"}},{"cell_type":"code","source":"# LSTM model\nearly_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n# def create_lstm_model():\n#     # model = Sequential([\n#     #     Embedding(input_dim=MAX_WORDS, output_dim=EMBEDDING_DIMS, input_length=MAX_LEN),\n#     #     LSTM(128, dropout=0.2, recurrent_dropout=0.2),\n#     #     Dense(1, activation='sigmoid')\n#     # ])\n#     model = Sequential([\n#     Embedding(input_dim=MAX_WORDS, output_dim=128, input_length=MAX_LEN),\n\n#     Bidirectional(GRU(64, return_sequences=True)),  \n#     Dropout(0.3),\n#     BatchNormalization(),\n\n#     Bidirectional(GRU(32)),  \n#     Dropout(0.3),\n#     BatchNormalization(),\n\n#     Dense(32, activation=\"relu\"),\n#     Dropout(0.3),\n\n#     Dense(1, activation=\"sigmoid\")  \n# ])\n#     model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n#     return model\n\nfrom tensorflow.keras.layers import Bidirectional, LSTM, Dropout, BatchNormalization, Dense\nfrom tensorflow.keras.regularizers import l2\n\ndef create_lstm_model():\n    model = Sequential([\n        # Embedding with a slightly smaller dimension\n        Embedding(input_dim=MAX_WORDS, output_dim=64, mask_zero=True),\n\n        # Optimized bidirectional LSTM\n        Bidirectional(LSTM(32, return_sequences=True)),  \n        BatchNormalization(),\n\n        Bidirectional(LSTM(16)),  \n        Dropout(0.1),  \n\n        # Dense layers with reduced regularization\n        Dense(16, activation=\"relu\"),  \n        BatchNormalization(),\n\n        # Output layer\n        Dense(1, activation=\"sigmoid\")\n    ])\n    \n    model.compile(\n        optimizer=Adam(learning_rate=1e-4),\n        loss='binary_crossentropy',\n        metrics=['accuracy']\n    )\n    return model","metadata":{"id":"EMGKH8SIKQKC","trusted":true,"execution":{"iopub.status.busy":"2025-04-02T08:57:33.989272Z","iopub.execute_input":"2025-04-02T08:57:33.989647Z","iopub.status.idle":"2025-04-02T08:57:33.996173Z","shell.execute_reply.started":"2025-04-02T08:57:33.989614Z","shell.execute_reply":"2025-04-02T08:57:33.995009Z"}},"outputs":[],"execution_count":48},{"cell_type":"markdown","source":"## Train Model","metadata":{"id":"NtJgiPrHpPTw"}},{"cell_type":"markdown","source":"#### Train Vanilla RNN Model","metadata":{"id":"oDj4NdgSphCR"}},{"cell_type":"code","source":"# Convert text data to sequences of integers using the tokenizer\nX_train_seq = tokenizer.texts_to_sequences(X_train)\nX_test_seq = tokenizer.texts_to_sequences(X_test)\n\n# Padding sequence\nX_train_pad = pad_sequences(X_train_seq, maxlen=MAX_LEN, padding=\"post\")\nX_test_pad = pad_sequences(X_test_seq, maxlen=MAX_LEN, padding=\"post\")\n","metadata":{"id":"dJwoU1zVqCx9","trusted":true,"execution":{"iopub.status.busy":"2025-04-02T09:19:27.303769Z","iopub.execute_input":"2025-04-02T09:19:27.304178Z","iopub.status.idle":"2025-04-02T09:19:31.392631Z","shell.execute_reply.started":"2025-04-02T09:19:27.304146Z","shell.execute_reply":"2025-04-02T09:19:31.391602Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"# Train Vanilla RNN model\nrnn_model = create_rnn_model()\nX_train_tensor = np.array(X_train_pad, dtype=np.int32)  \ny_train_tensor = np.array(y_train, dtype=np.float32)  \nX_test_tensor = np.array(X_test_pad, dtype=np.int32)\ny_test_tensor = np.array(y_test, dtype=np.float32)\n\n# train model\nhistory_rnn = rnn_model.fit(\n    X_train_tensor, y_train_tensor,\n    validation_data=(X_test_tensor, y_test_tensor),\n    epochs=10, batch_size=64\n)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ysKbSojdaMOy","outputId":"ca85cd91-0ad1-4f1d-999a-5b657b457a24","trusted":true,"execution":{"iopub.status.busy":"2025-04-02T09:19:49.533362Z","iopub.execute_input":"2025-04-02T09:19:49.533704Z","iopub.status.idle":"2025-04-02T09:25:38.857908Z","shell.execute_reply.started":"2025-04-02T09:19:49.533674Z","shell.execute_reply":"2025-04-02T09:25:38.857186Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 53ms/step - accuracy: 0.5147 - loss: 0.7059 - val_accuracy: 0.5584 - val_loss: 0.6777\nEpoch 2/10\n\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 49ms/step - accuracy: 0.5741 - loss: 0.6701 - val_accuracy: 0.6096 - val_loss: 0.6427\nEpoch 3/10\n\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 49ms/step - accuracy: 0.6381 - loss: 0.6243 - val_accuracy: 0.6510 - val_loss: 0.6178\nEpoch 4/10\n\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 49ms/step - accuracy: 0.6866 - loss: 0.5789 - val_accuracy: 0.6856 - val_loss: 0.6013\nEpoch 5/10\n\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 49ms/step - accuracy: 0.7594 - loss: 0.5031 - val_accuracy: 0.7812 - val_loss: 0.5000\nEpoch 6/10\n\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 49ms/step - accuracy: 0.7548 - loss: 0.5071 - val_accuracy: 0.7036 - val_loss: 0.5839\nEpoch 7/10\n\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 48ms/step - accuracy: 0.7550 - loss: 0.5046 - val_accuracy: 0.6068 - val_loss: 0.8007\nEpoch 8/10\n\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 48ms/step - accuracy: 0.7664 - loss: 0.4881 - val_accuracy: 0.7532 - val_loss: 0.5021\nEpoch 9/10\n\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 48ms/step - accuracy: 0.7180 - loss: 0.5483 - val_accuracy: 0.7178 - val_loss: 0.5461\nEpoch 10/10\n\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 48ms/step - accuracy: 0.7949 - loss: 0.4403 - val_accuracy: 0.7618 - val_loss: 0.5036\n","output_type":"stream"}],"execution_count":60},{"cell_type":"markdown","source":"#### Train GRU Model","metadata":{"id":"KIJP9Mw-pL2X"}},{"cell_type":"code","source":"X_train_seq = tokenizer.texts_to_sequences(X_train)\nX_test_seq = tokenizer.texts_to_sequences(X_test)\n\n# Padding để các chuỗi có cùng độ dài\nX_train_pad = pad_sequences(X_train_seq, maxlen=MAX_LEN, padding=\"post\")\nX_test_pad = pad_sequences(X_test_seq, maxlen=MAX_LEN, padding=\"post\")\n","metadata":{"id":"buL9hbPfNpNF","trusted":true,"execution":{"iopub.status.busy":"2025-04-02T09:26:06.944593Z","iopub.execute_input":"2025-04-02T09:26:06.944965Z","iopub.status.idle":"2025-04-02T09:26:11.418199Z","shell.execute_reply.started":"2025-04-02T09:26:06.944933Z","shell.execute_reply":"2025-04-02T09:26:11.417442Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"# Train GRU model\nearly_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\ngru_model = create_gru_model()\nhistory_gru = gru_model.fit(X_train_pad, y_train, validation_data=(X_test_pad, y_test),\n                            epochs=10, batch_size=64, callbacks=[early_stopping])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZwCNr6KzKM5J","outputId":"b37c83a6-18e1-46b0-8d4f-6382f277e86c","trusted":true,"execution":{"iopub.status.busy":"2025-04-02T09:26:21.524536Z","iopub.execute_input":"2025-04-02T09:26:21.524827Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m307/704\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m20:49\u001b[0m 3s/step - accuracy: 0.5159 - loss: 0.8099","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# Define tokenizer (adjust num_words if needed)\ntokenizer = Tokenizer(num_words=MAX_WORDS, oov_token=\"<OOV>\")\ntokenizer.fit_on_texts(X_train)  # Fit tokenizer on training data\n\n# Convert text to sequences\nX_train_seq = tokenizer.texts_to_sequences(X_train)\nX_test_seq = tokenizer.texts_to_sequences(X_test)\n\n# Now pad the sequences\nX_train_pad = pad_sequences(X_train_seq, maxlen=MAX_LEN, padding='post')\nX_test_pad = pad_sequences(X_test_seq, maxlen=MAX_LEN, padding='post')","metadata":{"id":"y_sVC6OUot7r","trusted":true,"execution":{"iopub.status.busy":"2025-04-02T08:57:31.256168Z","iopub.status.idle":"2025-04-02T08:57:31.256556Z","shell.execute_reply":"2025-04-02T08:57:31.256381Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train LSTM model\nlstm_model = create_lstm_model()\nhistory_lstm = lstm_model.fit(X_train_pad, y_train, validation_data=(X_test_pad, y_test),\n                              epochs=10, batch_size=64, callbacks=[early_stopping])","metadata":{"id":"LModeSp7KOtp","trusted":true,"execution":{"iopub.status.busy":"2025-04-02T08:57:40.118372Z","iopub.execute_input":"2025-04-02T08:57:40.118717Z","iopub.status.idle":"2025-04-02T09:01:58.047331Z","shell.execute_reply.started":"2025-04-02T08:57:40.118691Z","shell.execute_reply":"2025-04-02T09:01:58.046458Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 59ms/step - accuracy: 0.5793 - loss: 0.7269 - val_accuracy: 0.8246 - val_loss: 0.3963\nEpoch 2/10\n\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 59ms/step - accuracy: 0.8566 - loss: 0.3401 - val_accuracy: 0.8796 - val_loss: 0.2849\nEpoch 3/10\n\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 60ms/step - accuracy: 0.9127 - loss: 0.2274 - val_accuracy: 0.8856 - val_loss: 0.2781\nEpoch 4/10\n\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 60ms/step - accuracy: 0.9309 - loss: 0.1857 - val_accuracy: 0.8800 - val_loss: 0.2856\nEpoch 5/10\n\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 61ms/step - accuracy: 0.9463 - loss: 0.1518 - val_accuracy: 0.8806 - val_loss: 0.3031\nEpoch 6/10\n\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 60ms/step - accuracy: 0.9572 - loss: 0.1250 - val_accuracy: 0.8790 - val_loss: 0.3422\n","output_type":"stream"}],"execution_count":49},{"cell_type":"markdown","source":"### Plot results","metadata":{"id":"_KTZ04s4Kcv0"}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Plot accuracy\nplt.plot(history_rnn.history['val_accuracy'], label=\"Vanilla RNN\")\nplt.plot(history_gru.history['val_accuracy'], label=\"GRU\")\nplt.plot(history_lstm.history['val_accuracy'], label=\"LSTM\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Validation Accuracy\")\nplt.legend()\nplt.title(\"Model Accuracy Comparison\")\nplt.show()\n","metadata":{"id":"ud3WSBKoaQJD","trusted":true,"execution":{"iopub.status.busy":"2025-04-02T08:57:31.258393Z","iopub.status.idle":"2025-04-02T08:57:31.258778Z","shell.execute_reply":"2025-04-02T08:57:31.258579Z"}},"outputs":[],"execution_count":null}]}