{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mswUN254nohl"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65tF4OMEnnBv"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "import torch\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, GlobalAveragePooling1D,GRU,LSTM,Bidirectional,Dropout,BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrN5IrI5nrFS"
      },
      "source": [
        "## Data Downloading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpEVfrAhozR3"
      },
      "outputs": [],
      "source": [
        "zip_path = \"/content/IMDB Dataset.csv.zip\"\n",
        "extract_to = \"data/\"\n",
        "# Open the zip file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    # Extract specific files\n",
        "    zip_ref.extract(\"IMDB Dataset.csv\", extract_to)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2akOz-h2qt2W"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv(\"data/IMDB Dataset.csv\")\n",
        "train_df, test_df = train_test_split(train_data, test_size=0.1, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8copO9053UjV",
        "outputId": "33746701-df03-4a05-f37b-74ce5c25ee54"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "# Tải stopwords nếu chưa có\n",
        "nltk.download(\"stopwords\")\n",
        "\n",
        "# Khai báo stopwords\n",
        "stop_words = set(stopwords.words(\"english\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGxSHk_bnxvq"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9721i6G3UjW"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"\\d+\", \"\", text)\n",
        "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "    text = \" \".join([word for word in text.split() if word not in stop_words])\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "train_df[\"review\"] = train_df[\"review\"].apply(preprocess_text)\n",
        "test_df[\"review\"] = test_df[\"review\"].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQqzwVCH3UjW",
        "outputId": "557615be-916d-42a0-ade6-f53e7849cd6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y_train type: <class 'numpy.ndarray'>\n",
            "Unique values in y_train: ['negative' 'positive']\n"
          ]
        }
      ],
      "source": [
        "# separate review and sentiment\n",
        "X_train = train_df[\"review\"].values\n",
        "y_train = train_df[\"sentiment\"].values\n",
        "X_test = test_df[\"review\"].values\n",
        "y_test = test_df[\"sentiment\"].values\n",
        "\n",
        "print(\"y_train type:\", type(y_train))\n",
        "print(\"Unique values in y_train:\", np.unique(y_train))\n",
        "\n",
        "# map 1->positive, 0->negative\n",
        "if y_train.dtype == 'O':\n",
        "    label_mapping = {'positive': 1, 'negative': 0}\n",
        "    y_train = np.array([label_mapping[label] for label in y_train], dtype=np.float32)\n",
        "    y_test = np.array([label_mapping[label] for label in y_test], dtype=np.float32)\n",
        "else:\n",
        "    y_train = y_train.astype(np.float32)\n",
        "    y_test = y_test.astype(np.float32)\n",
        "\n",
        "MAX_WORDS = 10000\n",
        "MAX_LEN = 500\n",
        "\n",
        "EMBEDDING_DIMS = 128\n",
        "\n",
        "# Tokenize\n",
        "tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiguYT6Lnzo-"
      },
      "source": [
        "## Build Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpsGImh3KVeP"
      },
      "source": [
        "#### Vanilla RNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJ3_ExCopnMR"
      },
      "outputs": [],
      "source": [
        "# Vanilla RNN model\n",
        "def create_rnn_model():\n",
        "    model = Sequential([\n",
        "        Embedding(input_dim=MAX_WORDS, output_dim=EMBEDDING_DIMS, mask_zero=True),  # mask_zero=True\n",
        "        SimpleRNN(128, dropout=0.2, recurrent_dropout=0.2, return_sequences=False),  # return_sequences=False -> output 2D\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfIbHpM1o4x1"
      },
      "outputs": [],
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peN4Yxi5KYRp"
      },
      "source": [
        "#### GRU Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCO7MXDuKGat"
      },
      "outputs": [],
      "source": [
        "\n",
        "# from tensorflow.keras.layers import GRU, Dense, Embedding, Bidirectional, BatchNormalization, Dropout\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.optimizers import Adam\n",
        "# from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# def create_gru_model():\n",
        "#     model = Sequential([\n",
        "#         # Embedding Layer với mask_zero để xử lý padding\n",
        "#         Embedding(\n",
        "#             input_dim=MAX_WORDS,\n",
        "#             output_dim=EMBEDDING_DIMS,\n",
        "#             input_length=MAX_LEN,\n",
        "#             mask_zero=True\n",
        "#         ),\n",
        "\n",
        "#         # Stacked Bidirectional GRU Layers\n",
        "#         GRU(\n",
        "#             128,\n",
        "#             return_sequences=True,\n",
        "#             dropout=0.3,          # Dropout cho đầu vào\n",
        "#             recurrent_dropout=0.2, # Dropout cho recurrent state\n",
        "#             kernel_regularizer=l2(1e-4)\n",
        "#         ),\n",
        "#         BatchNormalization(),\n",
        "\n",
        "#         GRU(\n",
        "#             64,\n",
        "#             return_sequences=False, # Layer cuối không cần return sequences\n",
        "#             dropout=0.2,\n",
        "#             recurrent_dropout=0.1\n",
        "#         ),\n",
        "#         Dropout(0.3),\n",
        "\n",
        "#         # Hidden Layers với regularization\n",
        "#         Dense(32, activation='relu', kernel_regularizer=l2(1e-4)),\n",
        "#         BatchNormalization(),\n",
        "#         Dropout(0.2),\n",
        "\n",
        "#         # Output Layer\n",
        "#         Dense(1, activation='sigmoid')\n",
        "#     ])\n",
        "\n",
        "#     # optimize\n",
        "#     optimizer = Adam(\n",
        "#         learning_rate=1e-3,\n",
        "#         clipnorm=1.0  # avoid exploding gradients\n",
        "#     )\n",
        "\n",
        "#     model.compile(\n",
        "#         optimizer=Adam(learning_rate=1e-4),\n",
        "#         loss='binary_crossentropy',\n",
        "#         metrics=['accuracy']\n",
        "#     )\n",
        "#     return model\n",
        "from tensorflow.keras.layers import GRU, Dense, Embedding, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def create_gru_model():\n",
        "    model = Sequential([\n",
        "        Embedding(\n",
        "            input_dim=MAX_WORDS,\n",
        "            output_dim=EMBEDDING_DIMS,\n",
        "            input_length=MAX_LEN,\n",
        "            mask_zero=True\n",
        "        ),\n",
        "\n",
        "        # Dropout cho embedding layer\n",
        "        Dropout(0.3),\n",
        "\n",
        "        # GRU Layer 1\n",
        "        GRU(\n",
        "            128,\n",
        "            return_sequences=True,\n",
        "            dropout=0.3,\n",
        "            recurrent_dropout=0.2,\n",
        "            kernel_regularizer=l2(1e-4)\n",
        "        ),\n",
        "        # GRU Layer 2\n",
        "        GRU(\n",
        "            64,\n",
        "            dropout=0.2,\n",
        "            recurrent_dropout=0.1\n",
        "        ),\n",
        "        # Hidden Layer với regularization\n",
        "        Dense(32, activation='relu', kernel_regularizer=l2(1e-4)),\n",
        "        Dropout(0.2),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=1e-4),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdcnRn5SpAYr"
      },
      "source": [
        "#### LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMGKH8SIKQKC"
      },
      "outputs": [],
      "source": [
        "# LSTM model\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "from tensorflow.keras.layers import Bidirectional, LSTM, Dropout, BatchNormalization, Dense\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "def create_lstm_model():\n",
        "    model = Sequential([\n",
        "        # embedding\n",
        "        Embedding(input_dim=MAX_WORDS, output_dim=64, mask_zero=True),\n",
        "\n",
        "        # optimized bidirectional LSTM\n",
        "        Bidirectional(LSTM(32, return_sequences=True)),\n",
        "        BatchNormalization(),\n",
        "\n",
        "        Bidirectional(LSTM(16)),\n",
        "        Dropout(0.1),\n",
        "\n",
        "        # dense layers with reduced regularization\n",
        "        Dense(16, activation=\"relu\"),\n",
        "        BatchNormalization(),\n",
        "\n",
        "        # Output layer\n",
        "        Dense(1, activation=\"sigmoid\")\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=1e-4),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtJgiPrHpPTw"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDj4NdgSphCR"
      },
      "source": [
        "#### Train Vanilla RNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJwoU1zVqCx9"
      },
      "outputs": [],
      "source": [
        "# convert text data to sequences of integers using the tokenizer\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "# padding sequence\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_LEN, padding=\"post\")\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=MAX_LEN, padding=\"post\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysKbSojdaMOy",
        "outputId": "e546ee95-ce6c-42f9-bd7f-5265c9a8d8de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 231ms/step - accuracy: 0.5164 - loss: 0.7055 - val_accuracy: 0.6064 - val_loss: 0.6708\n",
            "Epoch 2/10\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 233ms/step - accuracy: 0.6045 - loss: 0.6521 - val_accuracy: 0.7396 - val_loss: 0.5259\n",
            "Epoch 3/10\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 239ms/step - accuracy: 0.6976 - loss: 0.5691 - val_accuracy: 0.7732 - val_loss: 0.4873\n",
            "Epoch 4/10\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 236ms/step - accuracy: 0.7396 - loss: 0.5216 - val_accuracy: 0.7878 - val_loss: 0.4715\n",
            "Epoch 5/10\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 234ms/step - accuracy: 0.7936 - loss: 0.4564 - val_accuracy: 0.7188 - val_loss: 0.5567\n",
            "Epoch 6/10\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 234ms/step - accuracy: 0.7861 - loss: 0.4676 - val_accuracy: 0.8144 - val_loss: 0.4416\n",
            "Epoch 7/10\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 233ms/step - accuracy: 0.8183 - loss: 0.4242 - val_accuracy: 0.8094 - val_loss: 0.4578\n",
            "Epoch 8/10\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 233ms/step - accuracy: 0.7979 - loss: 0.4661 - val_accuracy: 0.7582 - val_loss: 0.5052\n",
            "Epoch 9/10\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 234ms/step - accuracy: 0.8013 - loss: 0.4419 - val_accuracy: 0.7674 - val_loss: 0.4932\n",
            "Epoch 10/10\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 231ms/step - accuracy: 0.8130 - loss: 0.4273 - val_accuracy: 0.7502 - val_loss: 0.5143\n"
          ]
        }
      ],
      "source": [
        "# train Vanilla RNN model\n",
        "rnn_model = create_rnn_model()\n",
        "X_train_tensor = np.array(X_train_pad, dtype=np.int32)\n",
        "y_train_tensor = np.array(y_train, dtype=np.float32)\n",
        "X_test_tensor = np.array(X_test_pad, dtype=np.int32)\n",
        "y_test_tensor = np.array(y_test, dtype=np.float32)\n",
        "\n",
        "# train model\n",
        "history_rnn = rnn_model.fit(\n",
        "    X_train_tensor, y_train_tensor,\n",
        "    validation_data=(X_test_tensor, y_test_tensor),\n",
        "    epochs=10, batch_size=64\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIJP9Mw-pL2X"
      },
      "source": [
        "#### Train GRU Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "buL9hbPfNpNF"
      },
      "outputs": [],
      "source": [
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "# padding\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_LEN, padding=\"post\")\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=MAX_LEN, padding=\"post\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwCNr6KzKM5J",
        "outputId": "3dac5d4f-d710-4765-f392-b37b7d15f312"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m817s\u001b[0m 2s/step - accuracy: 0.5560 - loss: 0.6965 - val_accuracy: 0.8276 - val_loss: 0.4052\n",
            "Epoch 2/5\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m867s\u001b[0m 2s/step - accuracy: 0.8353 - loss: 0.4059 - val_accuracy: 0.8600 - val_loss: 0.3388\n",
            "Epoch 3/5\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m810s\u001b[0m 2s/step - accuracy: 0.8714 - loss: 0.3312 - val_accuracy: 0.8772 - val_loss: 0.3064\n",
            "Epoch 4/5\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m862s\u001b[0m 2s/step - accuracy: 0.8860 - loss: 0.3029 - val_accuracy: 0.8842 - val_loss: 0.2923\n",
            "Epoch 5/5\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m864s\u001b[0m 2s/step - accuracy: 0.8987 - loss: 0.2749 - val_accuracy: 0.8858 - val_loss: 0.2842\n"
          ]
        }
      ],
      "source": [
        "# train GRU model\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "gru_model = create_gru_model()\n",
        "history_gru = gru_model.fit(X_train_pad, y_train, validation_data=(X_test_pad, y_test),\n",
        "                            epochs=5, batch_size=128, callbacks=[early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "y_sVC6OUot7r"
      },
      "outputs": [],
      "source": [
        "# Define tokenizer (adjust num_words if needed)\n",
        "tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(X_train)  # Fit tokenizer on training data\n",
        "\n",
        "# Convert text to sequences\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "# pad the sequences\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_LEN, padding='post')\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=MAX_LEN, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LModeSp7KOtp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46a1c515-b479-4542-c2df-43aa56055aa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m515s\u001b[0m 719ms/step - accuracy: 0.6215 - loss: 0.6568 - val_accuracy: 0.8374 - val_loss: 0.3744\n",
            "Epoch 2/5\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m525s\u001b[0m 744ms/step - accuracy: 0.8721 - loss: 0.3154 - val_accuracy: 0.8800 - val_loss: 0.2904\n",
            "Epoch 3/5\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m538s\u001b[0m 712ms/step - accuracy: 0.9226 - loss: 0.2097 - val_accuracy: 0.8850 - val_loss: 0.2761\n",
            "Epoch 4/5\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m513s\u001b[0m 727ms/step - accuracy: 0.9387 - loss: 0.1741 - val_accuracy: 0.8828 - val_loss: 0.2914\n",
            "Epoch 5/5\n",
            "\u001b[1m522/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2:06\u001b[0m 694ms/step - accuracy: 0.9552 - loss: 0.1379"
          ]
        }
      ],
      "source": [
        "# Train LSTM model\n",
        "lstm_model = create_lstm_model()\n",
        "history_lstm = lstm_model.fit(X_train_pad, y_train, validation_data=(X_test_pad, y_test),\n",
        "                              epochs=5, batch_size=64, callbacks=[early_stopping])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KTZ04s4Kcv0"
      },
      "source": [
        "### Plot results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ud3WSBKoaQJD"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot accuracy\n",
        "plt.plot(history_rnn.history['val_accuracy'], label=\"Vanilla RNN\")\n",
        "plt.plot(history_gru.history['val_accuracy'], label=\"GRU\")\n",
        "plt.plot(history_lstm.history['val_accuracy'], label=\"LSTM\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Validation Accuracy\")\n",
        "plt.legend()\n",
        "plt.title(\"Model Accuracy Comparison\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewxBPo623UjY"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_accuracy(history):\n",
        "    \"\"\"\n",
        "    Plots training and validation accuracy over epochs.\n",
        "\n",
        "    Parameters:\n",
        "    history (dict or keras.callbacks.History):\n",
        "        A dictionary or Keras History object containing 'accuracy' and 'val_accuracy'.\n",
        "    \"\"\"\n",
        "    if hasattr(history, 'history'):  # If it's a Keras History object, extract history\n",
        "        history = history.history\n",
        "\n",
        "    epochs = range(1, len(history['accuracy']) + 1)\n",
        "\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(epochs, history['accuracy'], label='Training Accuracy', marker='o')\n",
        "    plt.plot(epochs, history['val_accuracy'], label='Validation Accuracy', marker='s')\n",
        "\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Training vs Validation Accuracy')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oldlZej3UjY"
      },
      "outputs": [],
      "source": [
        "plot_accuracy(lstm_model.history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6TAk-pK3UjY"
      },
      "outputs": [],
      "source": [
        "plot_accuracy(rnn_model.history)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 7024930,
          "sourceId": 11243419,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30919,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}