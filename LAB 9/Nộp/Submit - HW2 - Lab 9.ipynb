{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xp45S3gm352a"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1c9AfTycjJg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import defaultdict\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "# from torchcrf import CRF\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZNuXmf038za"
      },
      "source": [
        "### Data Downloading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARzlzB6F4GXi"
      },
      "outputs": [],
      "source": [
        "# Download file from Google Drive link and extract it\n",
        "def download_and_extract_zip(drive_link, save_path=\"dataset.zip\", extract_to=\"dataset\"):\n",
        "\n",
        "    # get the file ID from the Google Drive link\n",
        "    file_id = drive_link.split(\"/d/\")[1].split(\"/\")[0]\n",
        "    download_url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "\n",
        "    # download the file\n",
        "    response = requests.get(download_url, stream=True)\n",
        "    if response.status_code == 200:\n",
        "        with open(save_path, \"wb\") as file:\n",
        "            for chunk in response.iter_content(1024):\n",
        "                file.write(chunk)\n",
        "        print(\"Download complete\")\n",
        "\n",
        "    # extract the ZIP file\n",
        "    with zipfile.ZipFile(save_path, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "    print(\"Extraction complete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMyk0Tj46whD"
      },
      "outputs": [],
      "source": [
        "# Load data from the extracted file, handling different encodings\n",
        "def load_data(file_path):\n",
        "    \n",
        "    encodings = [\"utf-8\", \"ISO-8859-1\", \"windows-1252\"]\n",
        "\n",
        "    for enc in encodings:\n",
        "        try:\n",
        "            with open(file_path, \"r\", encoding=enc) as file:\n",
        "                lines = file.readlines()\n",
        "            print(f\"File loaded successfully using encoding: {enc}\")\n",
        "            return lines\n",
        "        except UnicodeDecodeError:\n",
        "            print(f\"Failed to load with encoding: {enc}\")\n",
        "\n",
        "    raise ValueError(\"Unable to read file\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iG0BZNI44fOK",
        "outputId": "24ddcbc6-3ac3-448c-e6c2-0b2352aa0b9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Download complete.\n",
            "Extraction complete.\n",
            "Failed to load with encoding: utf-8, trying next...\n",
            "File loaded successfully using encoding: ISO-8859-1\n"
          ]
        }
      ],
      "source": [
        "# provide google drive link, extract and take the dataset\n",
        "drive_link = \"https://drive.google.com/file/d/1AhESU6mPPW_UeRG4y2ojlAuH8Vyf4NlB/view?usp=sharing\"\n",
        "\n",
        "download_and_extract_zip(drive_link)\n",
        "dataset_path = \"dataset/GMB_dataset.txt\"\n",
        "\n",
        "data = load_data(dataset_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9tQqr4d3_zr"
      },
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "P-D_-YaU7y0j",
        "outputId": "6ee86238-52e2-40d7-ec7e-27e1096daf47"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 66161,\n  \"fields\": [\n    {\n      \"column\": \"Index\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 66161,\n        \"samples\": [\n          \"25841\",\n          \"5476\",\n          \"49952\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sentence #\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2999,\n        \"samples\": [\n          \"1377.0\",\n          \"933.0\",\n          \"145.0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Word\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8765,\n        \"samples\": [\n          \"whether\",\n          \"factories\",\n          \"town\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"POS\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 42,\n        \"samples\": [\n          \"WDT\",\n          \"WP\",\n          \"NN\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tag\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"O\",\n          \"B-geo\",\n          \"B-org\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-3ea35f79-e5a4-4ae3-9e2e-dcf3b3e2d23a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Index</th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66156</th>\n",
              "      <td>66156</td>\n",
              "      <td>2999.0</td>\n",
              "      <td>be</td>\n",
              "      <td>VB</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66157</th>\n",
              "      <td>66157</td>\n",
              "      <td>2999.0</td>\n",
              "      <td>announced</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66158</th>\n",
              "      <td>66158</td>\n",
              "      <td>2999.0</td>\n",
              "      <td>within</td>\n",
              "      <td>IN</td>\n",
              "      <td>B-tim</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66159</th>\n",
              "      <td>66159</td>\n",
              "      <td>2999.0</td>\n",
              "      <td>days</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66160</th>\n",
              "      <td>66160</td>\n",
              "      <td>2999.0</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>66161 rows Ã— 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ea35f79-e5a4-4ae3-9e2e-dcf3b3e2d23a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3ea35f79-e5a4-4ae3-9e2e-dcf3b3e2d23a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3ea35f79-e5a4-4ae3-9e2e-dcf3b3e2d23a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-14708eec-8f1b-455d-a19d-41121c85e730\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-14708eec-8f1b-455d-a19d-41121c85e730')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-14708eec-8f1b-455d-a19d-41121c85e730 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_762b6eec-bea5-49e9-828e-9e4e35712203\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_762b6eec-bea5-49e9-828e-9e4e35712203 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "       Index Sentence #           Word  POS    Tag\n",
              "0          0        1.0      Thousands  NNS      O\n",
              "1          1        1.0             of   IN      O\n",
              "2          2        1.0  demonstrators  NNS      O\n",
              "3          3        1.0           have  VBP      O\n",
              "4          4        1.0        marched  VBN      O\n",
              "...      ...        ...            ...  ...    ...\n",
              "66156  66156     2999.0             be   VB      O\n",
              "66157  66157     2999.0      announced  VBN      O\n",
              "66158  66158     2999.0         within   IN  B-tim\n",
              "66159  66159     2999.0           days  NNS      O\n",
              "66160  66160     2999.0              .    .      O\n",
              "\n",
              "[66161 rows x 5 columns]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with open(\"dataset/GMB_dataset.txt\", \"r\", encoding=\"ISO-8859-1\") as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "# split lines into columns \n",
        "data = [line.strip().split() for line in lines if line.strip()]  # remove empty lines\n",
        "\n",
        "# convert data to DataFrame\n",
        "df = pd.DataFrame(data, columns=[\"Index\", \"Sentence #\", \"Word\", \"POS\", \"Tag\"])\n",
        "\n",
        "# remove the first row as the header row from file\n",
        "df = df.iloc[1:].reset_index(drop=True)\n",
        "\n",
        "# check\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89UMTHKQBsp6",
        "outputId": "8650a6d0-027d-4e23-cc72-38b7130f1b95"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['O', 'B-geo', 'B-gpe', 'B-per', 'I-geo', 'B-org', 'I-org', 'B-tim',\n",
              "       'B-art', 'I-art', 'I-per', 'I-gpe', 'I-tim', None, 'B-nat',\n",
              "       'B-eve', 'I-eve', 'I-nat'], dtype=object)"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# print unique tag\n",
        "df['Tag'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FUJ2XXu-hiQ",
        "outputId": "62502bc6-beda-4367-e5cc-e33e45aec9c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index         0\n",
            "Sentence #    0\n",
            "Word          0\n",
            "POS           0\n",
            "Tag           1\n",
            "dtype: int64\n",
            "Missing values per column:\n",
            " Index         0\n",
            "Sentence #    0\n",
            "Word          0\n",
            "POS           0\n",
            "Tag           0\n",
            "dtype: int64\n",
            "  Index Sentence #           Word  POS Tag\n",
            "0     0        1.0      Thousands  NNS   O\n",
            "1     1        1.0             of   IN   O\n",
            "2     2        1.0  demonstrators  NNS   O\n",
            "3     3        1.0           have  VBP   O\n",
            "4     4        1.0        marched  VBN   O\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-38-99d239a3a76c>:5: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df = df.fillna(method = 'ffill')\n"
          ]
        }
      ],
      "source": [
        "print(df.isnull().sum())  # check if any columns have missing values\n",
        "\n",
        "# fill missing values\n",
        "df = df.fillna(method = 'ffill')\n",
        "\n",
        "# check for missing values after processing\n",
        "print(\"Missing values per column:\\n\", df.isnull().sum())\n",
        "\n",
        "# print few head rows\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCiOZVDn_l1z",
        "outputId": "aa38f536-7480-4618-a399-838a9773ed41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Total sentences: 2999\n",
            "First 3 sentences and their tags:\n",
            "\n",
            "Sentence 1: ['Thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'London', 'to', 'protest', 'the', 'war', 'in', 'Iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'British', 'troops', 'from', 'that', 'country', '.']\n",
            "  Word: Thousands       | Tag: O\n",
            "  Word: of              | Tag: O\n",
            "  Word: demonstrators   | Tag: O\n",
            "  Word: have            | Tag: O\n",
            "  Word: marched         | Tag: O\n",
            "  Word: through         | Tag: O\n",
            "  Word: London          | Tag: B-geo\n",
            "  Word: to              | Tag: O\n",
            "  Word: protest         | Tag: O\n",
            "  Word: the             | Tag: O\n",
            "  Word: war             | Tag: O\n",
            "  Word: in              | Tag: O\n",
            "  Word: Iraq            | Tag: B-geo\n",
            "  Word: and             | Tag: O\n",
            "  Word: demand          | Tag: O\n",
            "  Word: the             | Tag: O\n",
            "  Word: withdrawal      | Tag: O\n",
            "  Word: of              | Tag: O\n",
            "  Word: British         | Tag: B-gpe\n",
            "  Word: troops          | Tag: O\n",
            "  Word: from            | Tag: O\n",
            "  Word: that            | Tag: O\n",
            "  Word: country         | Tag: O\n",
            "  Word: .               | Tag: O\n",
            "\n",
            "Sentence 2: ['Families', 'of', 'soldiers', 'killed', 'in', 'the', 'conflict', 'joined', 'the', 'protesters', 'who', 'carried', 'banners', 'with', 'such', 'slogans', 'as', '\"\"\"\"', 'Bush', 'Number', 'One', 'Terrorist', '\"\"\"\"', 'and', '\"\"\"\"', 'Stop', 'the', 'Bombings', '.', '\"\"\"\"']\n",
            "  Word: Families        | Tag: O\n",
            "  Word: of              | Tag: O\n",
            "  Word: soldiers        | Tag: O\n",
            "  Word: killed          | Tag: O\n",
            "  Word: in              | Tag: O\n",
            "  Word: the             | Tag: O\n",
            "  Word: conflict        | Tag: O\n",
            "  Word: joined          | Tag: O\n",
            "  Word: the             | Tag: O\n",
            "  Word: protesters      | Tag: O\n",
            "  Word: who             | Tag: O\n",
            "  Word: carried         | Tag: O\n",
            "  Word: banners         | Tag: O\n",
            "  Word: with            | Tag: O\n",
            "  Word: such            | Tag: O\n",
            "  Word: slogans         | Tag: O\n",
            "  Word: as              | Tag: O\n",
            "  Word: \"\"\"\"            | Tag: O\n",
            "  Word: Bush            | Tag: B-per\n",
            "  Word: Number          | Tag: O\n",
            "  Word: One             | Tag: O\n",
            "  Word: Terrorist       | Tag: O\n",
            "  Word: \"\"\"\"            | Tag: O\n",
            "  Word: and             | Tag: O\n",
            "  Word: \"\"\"\"            | Tag: O\n",
            "  Word: Stop            | Tag: O\n",
            "  Word: the             | Tag: O\n",
            "  Word: Bombings        | Tag: O\n",
            "  Word: .               | Tag: O\n",
            "  Word: \"\"\"\"            | Tag: O\n",
            "\n",
            "Sentence 3: ['They', 'marched', 'from', 'the', 'Houses', 'of', 'Parliament', 'to', 'a', 'rally', 'in', 'Hyde', 'Park', '.']\n",
            "  Word: They            | Tag: O\n",
            "  Word: marched         | Tag: O\n",
            "  Word: from            | Tag: O\n",
            "  Word: the             | Tag: O\n",
            "  Word: Houses          | Tag: O\n",
            "  Word: of              | Tag: O\n",
            "  Word: Parliament      | Tag: O\n",
            "  Word: to              | Tag: O\n",
            "  Word: a               | Tag: O\n",
            "  Word: rally           | Tag: O\n",
            "  Word: in              | Tag: O\n",
            "  Word: Hyde            | Tag: B-geo\n",
            "  Word: Park            | Tag: I-geo\n",
            "  Word: .               | Tag: O\n"
          ]
        }
      ],
      "source": [
        "# group words and tags by sentence\n",
        "sentences = []\n",
        "tags = []\n",
        "sentence_dict = defaultdict(list)\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    sentence_dict[row[\"Sentence #\"]].append((row[\"Word\"], row[\"Tag\"]))\n",
        "\n",
        "# convert to list of sentences\n",
        "for sentence_id, values in sentence_dict.items():\n",
        "    words, ner_tags = zip(*values)\n",
        "    sentences.append(list(words))\n",
        "    tags.append(list(ner_tags))\n",
        "\n",
        "# print the converted lists\n",
        "print(\"\\nTotal sentences:\", len(sentences))\n",
        "print(\"first 3 sentences and their tags:\")\n",
        "for i, (sentence, tag_list) in enumerate(zip(sentences[:3], tags[:3])):\n",
        "    print(f\"\\nSentence {i+1}:\", sentence)\n",
        "    for word, tag in zip(sentence, tag_list):\n",
        "        print(f\"  Word: {word.ljust(15)} | Tag: {tag}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYEAREOzQE3j",
        "outputId": "cf5e29a7-2874-42bd-a4e9-b53bf8679489"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentences count: 2999\n",
            "Tags count: 2999\n"
          ]
        }
      ],
      "source": [
        "# check length of sentences and tags\n",
        "print(\"Sentences count:\", len(sentences))\n",
        "print(\"Tags count:\", len(tags))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHAGqxKSGpte"
      },
      "outputs": [],
      "source": [
        "# get unique words and labels from data\n",
        "words = list(df['Word'].unique())\n",
        "unique_tags = list(df['Tag'].unique())\n",
        "# dictionary word:index pair\n",
        "# word is key and its value is corresponding index\n",
        "word_to_index = {w : i + 2 for i, w in enumerate(words)}\n",
        "word_to_index[\"UNK\"] = 1\n",
        "word_to_index[\"PAD\"] = 0\n",
        "\n",
        "# dictionary label:index pair\n",
        "# label is key and value is index.\n",
        "tag_to_index = {t : i + 1 for i, t in enumerate(unique_tags)}\n",
        "tag_to_index[\"PAD\"] = 0\n",
        "\n",
        "idx2word = {i: w for w, i in word_to_index.items()}\n",
        "idx2tag = {i: w for w, i in tag_to_index.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtHdBTy4OEd8",
        "outputId": "c1f89a80-4f50-44f0-c457-bb9a0e15405b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique tags in dataset: {'B-per', 'I-tim', 'B-art', 'I-art', 'B-eve', 'I-gpe', 'I-eve', 'I-geo', 'B-tim', 'I-per', 'I-org', 'B-nat', 'I-nat', 'B-org', 'O', 'B-geo', 'B-gpe'}\n",
            "Keys in tag_to_index: dict_keys(['O', 'B-geo', 'B-gpe', 'B-per', 'I-geo', 'B-org', 'I-org', 'B-tim', 'B-art', 'I-art', 'I-per', 'I-gpe', 'I-tim', 'B-nat', 'B-eve', 'I-eve', 'I-nat', 'PAD'])\n"
          ]
        }
      ],
      "source": [
        "# check all unique tags in your dataset\n",
        "all_tags = set(tag for tag_list in tags for tag in tag_list)\n",
        "print(\"Unique tags in dataset:\", all_tags)\n",
        "\n",
        "# Check keys in your tag_to_index dictionary\n",
        "print(\"Keys in tag_to_index:\", tag_to_index.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnIgOb22Jp9y"
      },
      "outputs": [],
      "source": [
        "all_tags = sorted(set(tag for tag_list in tags for tag in tag_list))\n",
        "all_tags.append(\"PAD\")  # add padding token\n",
        "tag_to_index = {tag: idx for idx, tag in enumerate(all_tags)}\n",
        "\n",
        "max_len = 100\n",
        "# convert tags to indices\n",
        "y = [[tag_to_index[tag] for tag in sentence_tags] for sentence_tags in tags]\n",
        "\n",
        "# pad sequences\n",
        "y = pad_sequences(\n",
        "    maxlen=max_len,\n",
        "    sequences=y,\n",
        "    padding=\"post\",\n",
        "    value=tag_to_index[\"PAD\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wy3QdNH0G9Ow",
        "outputId": "c3b780d2-2290-494b-9d58-475936e795cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples in X: 2999\n",
            "Number of samples in y: 2999\n"
          ]
        }
      ],
      "source": [
        "# convert sentences to word indices\n",
        "X = [[word_to_index.get(word, word_to_index[\"UNK\"]) for word in sentence] for sentence in sentences]\n",
        "\n",
        "# convert tags to tag indices\n",
        "y = [[tag_to_index[tag] for tag in tag_list] for tag_list in tags]\n",
        "\n",
        "# check size\n",
        "print(\"Number of samples in X:\", len(X))\n",
        "print(\"Number of samples in y:\", len(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JuIfqlgnG_hY"
      },
      "outputs": [],
      "source": [
        "# split train and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "EKPQhHaoJsma",
        "outputId": "f8729f98-581b-4544-c357-b1598fe0fc01"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2699,) + inhomogeneous part.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-f2e7ee7ea019>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Size of training input data : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2699,) + inhomogeneous part."
          ]
        }
      ],
      "source": [
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "print(\"Size of training input data : \", X_train.shape)\n",
        "print(\"Size of training output data : \", np.array(y_train).shape)\n",
        "print(\"Size of testing input data : \", X_test.shape)\n",
        "print(\"Size of testing output data : \", np.array(y_test).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgSVcE6D4BYn"
      },
      "source": [
        "### Build Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvFobOwt4DGO"
      },
      "source": [
        "### Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXW_lJcW4EdF"
      },
      "source": [
        "### Conclusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euzv-VNHROcQ",
        "outputId": "7caeaf80-4a46-4e24-968d-dfd9661a8a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total sentences: 2999 (Tags: 2999)\n",
            "\n",
            "Final shapes:\n",
            "X_train: (2699, 70), y_train: (2699, 70)\n",
            "X_test: (300, 70), y_test: (300, 70)\n",
            "\n",
            "Sample sentence: ['Thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'London', 'to', 'protest', 'the', 'war', 'in', 'Iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'British', 'troops', 'from', 'that', 'country', '.']\n",
            "Mapped indices: [4058 8052 2420  777  896  667 4196 2186 1819 5455  985 1819 4638 6619\n",
            " 5872 5131 7613 6750  804 7042 3476 4830   50 7028 6480 3892 1129  490\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
            "Sample tags: ['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O']\n",
            "Mapped tags: [15 15 15 15 15 15 15 15 15  1 10 15 15 15 14 11 15 15  1 15 15 15 15 15\n",
            "  9  2 15 15  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Load your dataset\n",
        "# df = pd.read_csv(\"your_data.csv\")  # Uncomment if loading from file\n",
        "\n",
        "# 1. Group words and tags by sentence\n",
        "sentence_dict = defaultdict(list)\n",
        "for _, row in df.iterrows():\n",
        "    sentence_id = row[\"Sentence #\"]\n",
        "    sentence_dict[sentence_id].append((row[\"Word\"], row[\"Tag\"]))\n",
        "\n",
        "# 2. Extract aligned sentences and tags\n",
        "sentences, tags = [], []\n",
        "for sentence_id, values in sentence_dict.items():\n",
        "    words, ner_tags = zip(*values)  # Unpack word-tag pairs\n",
        "    sentences.append(list(words))\n",
        "    tags.append(list(ner_tags))\n",
        "\n",
        "# Verify alignment\n",
        "assert len(sentences) == len(tags), \"Sentences and tags mismatch!\"\n",
        "print(f\"Total sentences: {len(sentences)} (Tags: {len(tags)})\")\n",
        "\n",
        "# 3. Create vocabulary mappings\n",
        "# Word vocabulary\n",
        "all_words = set(word for sentence in sentences for word in sentence)\n",
        "word_to_index = {\n",
        "    \"PAD\": 0,\n",
        "    \"UNK\": 1,\n",
        "    **{word: idx+2 for idx, word in enumerate(all_words)}\n",
        "}\n",
        "\n",
        "# Tag vocabulary\n",
        "all_tags = set(tag for tag_list in tags for tag in tag_list)\n",
        "tag_to_index = {\n",
        "    \"PAD\": 0,\n",
        "    **{tag: idx+1 for idx, tag in enumerate(all_tags)}\n",
        "}\n",
        "\n",
        "# 4. Convert to numerical indices\n",
        "X = [\n",
        "    [word_to_index.get(word, word_to_index[\"UNK\"]) for word in sentence]\n",
        "    for sentence in sentences\n",
        "]\n",
        "y = [\n",
        "    [tag_to_index[tag] for tag in tag_list]\n",
        "    for tag_list in tags\n",
        "]\n",
        "\n",
        "# 5. Split dataset FIRST (before padding)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 6. Pad sequences AFTER splitting\n",
        "max_len = max(len(s) for s in X_train)  # Or set your preferred max length\n",
        "\n",
        "X_train = pad_sequences(\n",
        "    X_train, maxlen=max_len, padding=\"post\", value=word_to_index[\"PAD\"]\n",
        ")\n",
        "X_test = pad_sequences(\n",
        "    X_test, maxlen=max_len, padding=\"post\", value=word_to_index[\"PAD\"]\n",
        ")\n",
        "\n",
        "y_train = pad_sequences(\n",
        "    y_train, maxlen=max_len, padding=\"post\", value=tag_to_index[\"PAD\"]\n",
        ")\n",
        "y_test = pad_sequences(\n",
        "    y_test, maxlen=max_len, padding=\"post\", value=tag_to_index[\"PAD\"]\n",
        ")\n",
        "\n",
        "# 7. Final verification\n",
        "print(\"\\nFinal shapes:\")\n",
        "print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
        "print(f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
        "print(\"\\nSample sentence:\", sentences[0])\n",
        "print(\"Mapped indices:\", X_train[0])\n",
        "print(\"Sample tags:\", tags[0])\n",
        "print(\"Mapped tags:\", y_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5LFGO38WNvr",
        "outputId": "94ef524a-dbbc-4021-c7df-313c053a8745"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-crf in /usr/local/lib/python3.11/dist-packages (0.7.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-crf  # Correct package name  # Run this in Google Colab or your environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "yoz3V2EXWTFR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchcrf import CRF\n",
        "\n",
        "class BiLSTM_CRF(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_tags):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(\n",
        "            embedding_dim,\n",
        "            hidden_dim // 2,  # Bidirectional split\n",
        "            bidirectional=True,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.fc = nn.Linear(hidden_dim, num_tags)\n",
        "        self.crf = CRF(num_tags, batch_first=True)\n",
        "\n",
        "    def forward(self, x, tags=None, mask=None):\n",
        "        x = self.embedding(x)\n",
        "        x, _ = self.lstm(x)\n",
        "        emissions = self.fc(x)\n",
        "\n",
        "        if tags is not None:\n",
        "            loss = -self.crf(emissions, tags, mask=mask)\n",
        "            return loss\n",
        "        else:\n",
        "            return self.crf.decode(emissions, mask=mask)\n",
        "\n",
        "# Initialize model\n",
        "vocab_size = len(word_to_index)  # From preprocessing\n",
        "num_tags = len(tag_to_index)     # From preprocessing\n",
        "model = BiLSTM_CRF(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=100,\n",
        "    hidden_dim=50,\n",
        "    num_tags=num_tags\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cYtObGAXt8v",
        "outputId": "197e859a-1d96-4922-aed3-6217b5a4cf7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Batch: 000 | Loss: 1852.913\n",
            "Epoch: 01 | Batch: 010 | Loss: 600.430\n",
            "Epoch: 01 | Batch: 020 | Loss: 571.082\n",
            "Epoch: 01 | Batch: 030 | Loss: 459.790\n",
            "Epoch: 01 | Batch: 040 | Loss: 474.414\n",
            "Epoch: 01 | Batch: 050 | Loss: 473.104\n",
            "Epoch: 01 | Batch: 060 | Loss: 432.323\n",
            "Epoch: 01 | Batch: 070 | Loss: 450.706\n",
            "Epoch: 01 | Batch: 080 | Loss: 372.644\n",
            "\n",
            "Epoch: 01 | Average Loss: 559.420\n",
            "\n",
            "Epoch: 02 | Batch: 000 | Loss: 467.115\n",
            "Epoch: 02 | Batch: 010 | Loss: 388.867\n",
            "Epoch: 02 | Batch: 020 | Loss: 469.439\n",
            "Epoch: 02 | Batch: 030 | Loss: 317.274\n",
            "Epoch: 02 | Batch: 040 | Loss: 386.415\n",
            "Epoch: 02 | Batch: 050 | Loss: 359.081\n",
            "Epoch: 02 | Batch: 060 | Loss: 358.313\n",
            "Epoch: 02 | Batch: 070 | Loss: 455.720\n",
            "Epoch: 02 | Batch: 080 | Loss: 355.959\n",
            "\n",
            "Epoch: 02 | Average Loss: 372.726\n",
            "\n",
            "Epoch: 03 | Batch: 000 | Loss: 346.928\n",
            "Epoch: 03 | Batch: 010 | Loss: 353.975\n",
            "Epoch: 03 | Batch: 020 | Loss: 226.234\n",
            "Epoch: 03 | Batch: 030 | Loss: 264.546\n",
            "Epoch: 03 | Batch: 040 | Loss: 356.678\n",
            "Epoch: 03 | Batch: 050 | Loss: 242.671\n",
            "Epoch: 03 | Batch: 060 | Loss: 310.205\n",
            "Epoch: 03 | Batch: 070 | Loss: 255.391\n",
            "Epoch: 03 | Batch: 080 | Loss: 258.256\n",
            "\n",
            "Epoch: 03 | Average Loss: 302.089\n",
            "\n",
            "Epoch: 04 | Batch: 000 | Loss: 307.873\n",
            "Epoch: 04 | Batch: 010 | Loss: 202.476\n",
            "Epoch: 04 | Batch: 020 | Loss: 293.111\n",
            "Epoch: 04 | Batch: 030 | Loss: 323.126\n",
            "Epoch: 04 | Batch: 040 | Loss: 268.550\n",
            "Epoch: 04 | Batch: 050 | Loss: 200.672\n",
            "Epoch: 04 | Batch: 060 | Loss: 301.569\n",
            "Epoch: 04 | Batch: 070 | Loss: 276.216\n",
            "Epoch: 04 | Batch: 080 | Loss: 183.072\n",
            "\n",
            "Epoch: 04 | Average Loss: 250.102\n",
            "\n",
            "Epoch: 05 | Batch: 000 | Loss: 241.212\n",
            "Epoch: 05 | Batch: 010 | Loss: 273.869\n",
            "Epoch: 05 | Batch: 020 | Loss: 197.718\n",
            "Epoch: 05 | Batch: 030 | Loss: 219.480\n",
            "Epoch: 05 | Batch: 040 | Loss: 202.489\n",
            "Epoch: 05 | Batch: 050 | Loss: 195.041\n",
            "Epoch: 05 | Batch: 060 | Loss: 141.712\n",
            "Epoch: 05 | Batch: 070 | Loss: 218.779\n",
            "Epoch: 05 | Batch: 080 | Loss: 202.576\n",
            "\n",
            "Epoch: 05 | Average Loss: 210.972\n",
            "\n",
            "Epoch: 06 | Batch: 000 | Loss: 192.930\n",
            "Epoch: 06 | Batch: 010 | Loss: 176.726\n",
            "Epoch: 06 | Batch: 020 | Loss: 184.701\n",
            "Epoch: 06 | Batch: 030 | Loss: 212.599\n",
            "Epoch: 06 | Batch: 040 | Loss: 208.833\n",
            "Epoch: 06 | Batch: 050 | Loss: 163.361\n",
            "Epoch: 06 | Batch: 060 | Loss: 144.424\n",
            "Epoch: 06 | Batch: 070 | Loss: 202.862\n",
            "Epoch: 06 | Batch: 080 | Loss: 205.500\n",
            "\n",
            "Epoch: 06 | Average Loss: 180.276\n",
            "\n",
            "Epoch: 07 | Batch: 000 | Loss: 182.186\n",
            "Epoch: 07 | Batch: 010 | Loss: 136.298\n",
            "Epoch: 07 | Batch: 020 | Loss: 198.052\n",
            "Epoch: 07 | Batch: 030 | Loss: 117.197\n",
            "Epoch: 07 | Batch: 040 | Loss: 147.634\n",
            "Epoch: 07 | Batch: 050 | Loss: 143.837\n",
            "Epoch: 07 | Batch: 060 | Loss: 169.582\n",
            "Epoch: 07 | Batch: 070 | Loss: 121.009\n",
            "Epoch: 07 | Batch: 080 | Loss: 124.578\n",
            "\n",
            "Epoch: 07 | Average Loss: 155.287\n",
            "\n",
            "Epoch: 08 | Batch: 000 | Loss: 176.641\n",
            "Epoch: 08 | Batch: 010 | Loss: 108.603\n",
            "Epoch: 08 | Batch: 020 | Loss: 116.670\n",
            "Epoch: 08 | Batch: 030 | Loss: 172.516\n",
            "Epoch: 08 | Batch: 040 | Loss: 152.146\n",
            "Epoch: 08 | Batch: 050 | Loss: 130.388\n",
            "Epoch: 08 | Batch: 060 | Loss: 112.862\n",
            "Epoch: 08 | Batch: 070 | Loss: 94.874\n",
            "Epoch: 08 | Batch: 080 | Loss: 91.909\n",
            "\n",
            "Epoch: 08 | Average Loss: 134.794\n",
            "\n",
            "Epoch: 09 | Batch: 000 | Loss: 108.403\n",
            "Epoch: 09 | Batch: 010 | Loss: 121.714\n",
            "Epoch: 09 | Batch: 020 | Loss: 116.010\n",
            "Epoch: 09 | Batch: 030 | Loss: 108.986\n",
            "Epoch: 09 | Batch: 040 | Loss: 145.123\n",
            "Epoch: 09 | Batch: 050 | Loss: 117.269\n",
            "Epoch: 09 | Batch: 060 | Loss: 151.588\n",
            "Epoch: 09 | Batch: 070 | Loss: 99.474\n",
            "Epoch: 09 | Batch: 080 | Loss: 146.849\n",
            "\n",
            "Epoch: 09 | Average Loss: 117.422\n",
            "\n",
            "Epoch: 10 | Batch: 000 | Loss: 97.539\n",
            "Epoch: 10 | Batch: 010 | Loss: 89.261\n",
            "Epoch: 10 | Batch: 020 | Loss: 83.877\n",
            "Epoch: 10 | Batch: 030 | Loss: 66.294\n",
            "Epoch: 10 | Batch: 040 | Loss: 76.581\n",
            "Epoch: 10 | Batch: 050 | Loss: 105.835\n",
            "Epoch: 10 | Batch: 060 | Loss: 135.881\n",
            "Epoch: 10 | Batch: 070 | Loss: 127.486\n",
            "Epoch: 10 | Batch: 080 | Loss: 71.748\n",
            "\n",
            "Epoch: 10 | Average Loss: 102.502\n",
            "\n",
            "Epoch: 11 | Batch: 000 | Loss: 66.449\n",
            "Epoch: 11 | Batch: 010 | Loss: 84.291\n",
            "Epoch: 11 | Batch: 020 | Loss: 75.192\n",
            "Epoch: 11 | Batch: 030 | Loss: 89.558\n",
            "Epoch: 11 | Batch: 040 | Loss: 110.333\n",
            "Epoch: 11 | Batch: 050 | Loss: 110.580\n",
            "Epoch: 11 | Batch: 060 | Loss: 91.466\n",
            "Epoch: 11 | Batch: 070 | Loss: 59.337\n",
            "Epoch: 11 | Batch: 080 | Loss: 60.343\n",
            "\n",
            "Epoch: 11 | Average Loss: 89.683\n",
            "\n",
            "Epoch: 12 | Batch: 000 | Loss: 69.692\n",
            "Epoch: 12 | Batch: 010 | Loss: 74.044\n",
            "Epoch: 12 | Batch: 020 | Loss: 42.038\n",
            "Epoch: 12 | Batch: 030 | Loss: 107.157\n",
            "Epoch: 12 | Batch: 040 | Loss: 58.006\n",
            "Epoch: 12 | Batch: 050 | Loss: 85.915\n",
            "Epoch: 12 | Batch: 060 | Loss: 68.369\n",
            "Epoch: 12 | Batch: 070 | Loss: 99.349\n",
            "Epoch: 12 | Batch: 080 | Loss: 74.791\n",
            "\n",
            "Epoch: 12 | Average Loss: 78.410\n",
            "\n",
            "Epoch: 13 | Batch: 000 | Loss: 72.123\n",
            "Epoch: 13 | Batch: 010 | Loss: 66.772\n",
            "Epoch: 13 | Batch: 020 | Loss: 57.549\n",
            "Epoch: 13 | Batch: 030 | Loss: 71.039\n",
            "Epoch: 13 | Batch: 040 | Loss: 54.729\n",
            "Epoch: 13 | Batch: 050 | Loss: 54.963\n",
            "Epoch: 13 | Batch: 060 | Loss: 64.348\n",
            "Epoch: 13 | Batch: 070 | Loss: 62.034\n",
            "Epoch: 13 | Batch: 080 | Loss: 43.595\n",
            "\n",
            "Epoch: 13 | Average Loss: 68.699\n",
            "\n",
            "Epoch: 14 | Batch: 000 | Loss: 60.173\n",
            "Epoch: 14 | Batch: 010 | Loss: 45.930\n",
            "Epoch: 14 | Batch: 020 | Loss: 70.444\n",
            "Epoch: 14 | Batch: 030 | Loss: 69.500\n",
            "Epoch: 14 | Batch: 040 | Loss: 67.298\n",
            "Epoch: 14 | Batch: 050 | Loss: 76.478\n",
            "Epoch: 14 | Batch: 060 | Loss: 55.845\n",
            "Epoch: 14 | Batch: 070 | Loss: 64.333\n",
            "Epoch: 14 | Batch: 080 | Loss: 54.296\n",
            "\n",
            "Epoch: 14 | Average Loss: 60.022\n",
            "\n",
            "Epoch: 15 | Batch: 000 | Loss: 51.370\n",
            "Epoch: 15 | Batch: 010 | Loss: 37.005\n",
            "Epoch: 15 | Batch: 020 | Loss: 31.711\n",
            "Epoch: 15 | Batch: 030 | Loss: 49.052\n",
            "Epoch: 15 | Batch: 040 | Loss: 60.137\n",
            "Epoch: 15 | Batch: 050 | Loss: 71.422\n",
            "Epoch: 15 | Batch: 060 | Loss: 29.179\n",
            "Epoch: 15 | Batch: 070 | Loss: 45.893\n",
            "Epoch: 15 | Batch: 080 | Loss: 42.262\n",
            "\n",
            "Epoch: 15 | Average Loss: 52.463\n",
            "\n",
            "\n",
            "Sample prediction: [('EU', 'B-org'), ('rejects', 'O'), ('German', 'B-gpe'), ('call', 'B-org')]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchcrf import CRF\n",
        "\n",
        "# Assuming you have these from preprocessing\n",
        "# X_train_padded, y_train_padded (numpy arrays)\n",
        "# word_to_index, tag_to_index (dictionaries)\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.long)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "\n",
        "# Create mask tensor (1 for real tokens, 0 for padding)\n",
        "mask = (X_train_tensor != word_to_index[\"PAD\"]).bool()\n",
        "\n",
        "# Create dataset and dataloader\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor, mask)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Define model parameters\n",
        "vocab_size = len(word_to_index)\n",
        "num_tags = len(tag_to_index)\n",
        "embedding_dim = 100\n",
        "hidden_dim = 50\n",
        "\n",
        "# Initialize model, loss and optimizer\n",
        "model = BiLSTM_CRF(vocab_size, embedding_dim, hidden_dim, num_tags)\n",
        "optimizer = optim.RMSprop(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 15\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch_idx, (inputs, targets, mask_batch) in enumerate(train_loader):\n",
        "        # Zero gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        loss = model(inputs, tags=targets, mask=mask_batch)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Print batch progress\n",
        "        if batch_idx % 10 == 0:\n",
        "            print(f'Epoch: {epoch+1:02} | Batch: {batch_idx:03} | Loss: {loss.item():.3f}')\n",
        "\n",
        "    # Print epoch statistics\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f'\\nEpoch: {epoch+1:02} | Average Loss: {avg_loss:.3f}\\n')\n",
        "\n",
        "# Save model\n",
        "torch.save(model.state_dict(), \"bilstm_crf_ner_model.pt\")\n",
        "\n",
        "# Test prediction example\n",
        "def predict(sentence, model, word_to_index, tag_to_index):\n",
        "    # Convert sentence to indices\n",
        "    indexed_sentence = [word_to_index.get(word, word_to_index[\"UNK\"]) for word in sentence]\n",
        "\n",
        "    # Convert to tensor and add batch dimension\n",
        "    inputs = torch.tensor([indexed_sentence], dtype=torch.long)\n",
        "    mask = (inputs != word_to_index[\"PAD\"]).bool()\n",
        "\n",
        "    # Predict\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        tags = model(inputs, mask=mask)\n",
        "\n",
        "    # Convert indices to tags\n",
        "    index_to_tag = {v: k for k, v in tag_to_index.items()}\n",
        "    return [(word, index_to_tag[tag]) for word, tag in zip(sentence, tags[0])]\n",
        "\n",
        "# Test with sample input\n",
        "test_sentence = [\"EU\", \"rejects\", \"German\", \"call\"]\n",
        "print(\"\\nSample prediction:\", predict(test_sentence, model, word_to_index, tag_to_index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "0JHTWAZlaHbC"
      },
      "outputs": [],
      "source": [
        "# Convert test data to tensors\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.long)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "test_mask = (X_test_tensor != word_to_index[\"PAD\"]).bool()\n",
        "\n",
        "# # Create test DataLoader\n",
        "# test_dataset = TensorDataset(X_test_tensor, y_test_tensor, test_mask)\n",
        "# test_loader = DataLoader(test_dataset, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "B7irZ8tAbxZw"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, dataloader, tag_to_index):\n",
        "    model.eval()\n",
        "    total_correct = 0\n",
        "    total_tokens = 0\n",
        "\n",
        "    index_to_tag = {v: k for k, v in tag_to_index.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets, mask in dataloader:\n",
        "            # Get predictions (list of lists)\n",
        "            preds = model(inputs, mask=mask)\n",
        "\n",
        "            # Iterate through each sample in batch\n",
        "            for i in range(inputs.size(0)):\n",
        "                # Mask for current sample\n",
        "                sample_mask = mask[i]\n",
        "\n",
        "                # True tags (already indices)\n",
        "                true_tags = targets[i][sample_mask]\n",
        "\n",
        "                # Predicted tags (convert from list to tensor)\n",
        "                pred_tags = torch.tensor(preds[i][:len(true_tags)], device=inputs.device)\n",
        "\n",
        "                # Calculate correct predictions\n",
        "                total_correct += (pred_tags == true_tags).sum().item()\n",
        "                total_tokens += len(true_tags)\n",
        "\n",
        "    accuracy = total_correct / total_tokens\n",
        "    print(f\"Token Accuracy: {accuracy:.4f}\")\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yp_bGyehcGC9",
        "outputId": "b6705368-5e9e-4260-9297-477977dfe097"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token Accuracy: 0.9325\n"
          ]
        }
      ],
      "source": [
        "# Ensure test_loader is properly defined:\n",
        "test_loader = DataLoader(\n",
        "    TensorDataset(X_test_tensor, y_test_tensor, test_mask),\n",
        "    batch_size=64\n",
        ")\n",
        "\n",
        "# Run evaluation\n",
        "results = evaluate(model, test_loader, tag_to_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRtGujEuivfh",
        "outputId": "a4bb59e0-c846-495e-b2cd-c983b2bfc584"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted Tags:\n",
            "Apple: B-per\n",
            "Inc.: I-per\n",
            "is: O\n",
            "based: O\n",
            "in: O\n",
            "California: B-geo\n"
          ]
        }
      ],
      "source": [
        "test_sentence = [\"Apple\", \"Inc.\", \"is\", \"based\", \"in\", \"California\"]\n",
        "# Use the predict function\n",
        "prediction = predict(test_sentence, model, word_to_index, tag_to_index)\n",
        "\n",
        "# Print results\n",
        "print(\"Predicted Tags:\")\n",
        "for word, tag in prediction:\n",
        "    print(f\"{word}: {tag}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
