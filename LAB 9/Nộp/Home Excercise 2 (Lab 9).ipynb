{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xp45S3gm352a"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 397,
      "metadata": {
        "id": "Y1c9AfTycjJg"
      },
      "outputs": [],
      "source": [
        "# use for file handling, downloading and extracting data\n",
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "# data processing and numerical computations\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import defaultdict\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# TensorFlow Keras, use pad_sequences to ensure uniform input sizes\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZNuXmf038za"
      },
      "source": [
        "### Data Downloading"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Upload dataset to Google Drive, then download, extract and load data"
      ],
      "metadata": {
        "id": "nFfjmehO-ltL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 398,
      "metadata": {
        "id": "ARzlzB6F4GXi"
      },
      "outputs": [],
      "source": [
        "# download file from Google Drive link and extract it\n",
        "def download_and_extract_zip(drive_link, save_path=\"dataset.zip\", extract_to=\"dataset\"):\n",
        "\n",
        "    # get the file ID from the Google Drive link\n",
        "    file_id = drive_link.split(\"/d/\")[1].split(\"/\")[0]\n",
        "    download_url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "\n",
        "    # download the file\n",
        "    response = requests.get(download_url, stream=True)\n",
        "    if response.status_code == 200:\n",
        "        with open(save_path, \"wb\") as file:\n",
        "            for chunk in response.iter_content(1024):\n",
        "                file.write(chunk)\n",
        "        print(\"Download complete\")\n",
        "\n",
        "    # extract the ZIP file\n",
        "    with zipfile.ZipFile(save_path, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "    print(\"Extraction complete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 399,
      "metadata": {
        "id": "LMyk0Tj46whD"
      },
      "outputs": [],
      "source": [
        "# load data from the extracted file, handling different encodings\n",
        "def load_data(file_path):\n",
        "\n",
        "    encodings = [\"utf-8\", \"ISO-8859-1\", \"windows-1252\"]\n",
        "\n",
        "    for enc in encodings:\n",
        "        try:\n",
        "            with open(file_path, \"r\", encoding=enc) as file:\n",
        "                lines = file.readlines()\n",
        "            print(f\"File loaded successfully using encoding: {enc}\")\n",
        "            return lines\n",
        "        except UnicodeDecodeError:\n",
        "            print(f\"Failed to load with encoding: {enc}\")\n",
        "\n",
        "    raise ValueError(\"Unable to read file\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 400,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iG0BZNI44fOK",
        "outputId": "873243a5-b816-4d8d-ddbb-043e0ea41101"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download complete\n",
            "Extraction complete\n",
            "Failed to load with encoding: utf-8\n",
            "File loaded successfully using encoding: ISO-8859-1\n"
          ]
        }
      ],
      "source": [
        "# get Google Drive link, extract and take the dataset\n",
        "drive_link = \"https://drive.google.com/file/d/1AhESU6mPPW_UeRG4y2ojlAuH8Vyf4NlB/view?usp=sharing\"\n",
        "download_and_extract_zip(drive_link)\n",
        "\n",
        "# load dataset\n",
        "dataset_path = \"dataset/GMB_dataset.txt\"\n",
        "data = load_data(dataset_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9tQqr4d3_zr"
      },
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 401,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "P-D_-YaU7y0j",
        "outputId": "2f112bca-1f8c-442f-a4f4-0b8aa2e601d1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Index Sentence #           Word  POS    Tag\n",
              "0          0        1.0      Thousands  NNS      O\n",
              "1          1        1.0             of   IN      O\n",
              "2          2        1.0  demonstrators  NNS      O\n",
              "3          3        1.0           have  VBP      O\n",
              "4          4        1.0        marched  VBN      O\n",
              "...      ...        ...            ...  ...    ...\n",
              "66156  66156     2999.0             be   VB      O\n",
              "66157  66157     2999.0      announced  VBN      O\n",
              "66158  66158     2999.0         within   IN  B-tim\n",
              "66159  66159     2999.0           days  NNS      O\n",
              "66160  66160     2999.0              .    .      O\n",
              "\n",
              "[66161 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fed6890e-0f4f-4e2d-ad82-ff8d8a243480\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Index</th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66156</th>\n",
              "      <td>66156</td>\n",
              "      <td>2999.0</td>\n",
              "      <td>be</td>\n",
              "      <td>VB</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66157</th>\n",
              "      <td>66157</td>\n",
              "      <td>2999.0</td>\n",
              "      <td>announced</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66158</th>\n",
              "      <td>66158</td>\n",
              "      <td>2999.0</td>\n",
              "      <td>within</td>\n",
              "      <td>IN</td>\n",
              "      <td>B-tim</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66159</th>\n",
              "      <td>66159</td>\n",
              "      <td>2999.0</td>\n",
              "      <td>days</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66160</th>\n",
              "      <td>66160</td>\n",
              "      <td>2999.0</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>66161 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fed6890e-0f4f-4e2d-ad82-ff8d8a243480')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fed6890e-0f4f-4e2d-ad82-ff8d8a243480 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fed6890e-0f4f-4e2d-ad82-ff8d8a243480');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-34229c5b-ef58-436c-a2ef-88b5cce2084a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-34229c5b-ef58-436c-a2ef-88b5cce2084a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-34229c5b-ef58-436c-a2ef-88b5cce2084a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_7d898c61-ad72-4eac-aee9-7dcf884ed109\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7d898c61-ad72-4eac-aee9-7dcf884ed109 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 66161,\n  \"fields\": [\n    {\n      \"column\": \"Index\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 66161,\n        \"samples\": [\n          \"25841\",\n          \"5476\",\n          \"49952\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sentence #\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2999,\n        \"samples\": [\n          \"1377.0\",\n          \"933.0\",\n          \"145.0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Word\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8765,\n        \"samples\": [\n          \"whether\",\n          \"factories\",\n          \"town\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"POS\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 42,\n        \"samples\": [\n          \"WDT\",\n          \"WP\",\n          \"NN\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tag\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"O\",\n          \"B-geo\",\n          \"B-org\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 401
        }
      ],
      "source": [
        "with open(\"dataset/GMB_dataset.txt\", \"r\", encoding=\"ISO-8859-1\") as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "# split lines into columns\n",
        "data = [line.strip().split() for line in lines if line.strip()]  # remove empty lines\n",
        "\n",
        "# convert data to DataFrame\n",
        "df = pd.DataFrame(data, columns=[\"Index\", \"Sentence #\", \"Word\", \"POS\", \"Tag\"])\n",
        "\n",
        "# remove the first row as the header row from file\n",
        "df = df.iloc[1:].reset_index(drop=True)\n",
        "\n",
        "# check format\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 402,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89UMTHKQBsp6",
        "outputId": "2e26f4a7-0d7f-4363-8570-93d9d4db0d7f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['O', 'B-geo', 'B-gpe', 'B-per', 'I-geo', 'B-org', 'I-org', 'B-tim',\n",
              "       'B-art', 'I-art', 'I-per', 'I-gpe', 'I-tim', None, 'B-nat',\n",
              "       'B-eve', 'I-eve', 'I-nat'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 402
        }
      ],
      "source": [
        "# print unique tag\n",
        "df['Tag'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 403,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FUJ2XXu-hiQ",
        "outputId": "577afab6-3c89-4b5c-c57b-92607b756ecb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index         0\n",
            "Sentence #    0\n",
            "Word          0\n",
            "POS           0\n",
            "Tag           1\n",
            "dtype: int64\n",
            "Missing values per column:\n",
            " Index         0\n",
            "Sentence #    0\n",
            "Word          0\n",
            "POS           0\n",
            "Tag           0\n",
            "dtype: int64\n",
            "  Index Sentence #           Word  POS Tag\n",
            "0     0        1.0      Thousands  NNS   O\n",
            "1     1        1.0             of   IN   O\n",
            "2     2        1.0  demonstrators  NNS   O\n",
            "3     3        1.0           have  VBP   O\n",
            "4     4        1.0        marched  VBN   O\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-403-b6a57498f5e1>:4: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df = df.fillna(method = 'ffill')\n"
          ]
        }
      ],
      "source": [
        "print(df.isnull().sum())  # check if any columns have missing values\n",
        "\n",
        "# fill missing values\n",
        "df = df.fillna(method = 'ffill')\n",
        "\n",
        "# check for missing values after processing\n",
        "print(\"Missing values per column:\\n\", df.isnull().sum())\n",
        "\n",
        "# print few head rows\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# group words and tags by sentence\n",
        "sentence_dict = defaultdict(list)\n",
        "for _, row in df.iterrows():\n",
        "    sentence_id = row[\"Sentence #\"]\n",
        "    sentence_dict[sentence_id].append((row[\"Word\"], row[\"Tag\"]))"
      ],
      "metadata": {
        "id": "jnbHwvCD2Rhr"
      },
      "execution_count": 404,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract aligned sentences and tags\n",
        "sentences, tags = [], []\n",
        "for sentence_id, values in sentence_dict.items():\n",
        "    words, ner_tags = zip(*values)  # unpack word-tag pairs\n",
        "    sentences.append(list(words))\n",
        "    tags.append(list(ner_tags))\n",
        "\n",
        "# check alignment\n",
        "assert len(sentences) == len(tags), \"Sentences and tags mismatch!\"\n",
        "print(f\"Total sentences: {len(sentences)} (Tags: {len(tags)})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlwlOua92Xzd",
        "outputId": "9556ab40-a63a-4fc6-ea23-fea13ad083f2"
      },
      "execution_count": 405,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total sentences: 2999 (Tags: 2999)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create vocabulary mappings\n",
        "\n",
        "# Word vocabulary\n",
        "all_words = set(word for sentence in sentences for word in sentence)\n",
        "word_to_index = {\n",
        "    \"PAD\": 0,\n",
        "    \"UNK\": 1,\n",
        "    **{word: idx+2 for idx, word in enumerate(all_words)}\n",
        "}\n",
        "\n",
        "# Tag vocabulary\n",
        "all_tags = set(tag for tag_list in tags for tag in tag_list)\n",
        "tag_to_index = {\n",
        "    \"PAD\": 0,\n",
        "    **{tag: idx+1 for idx, tag in enumerate(all_tags)}\n",
        "}"
      ],
      "metadata": {
        "id": "Fd9fIkPn24vi"
      },
      "execution_count": 406,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert to numerical indices\n",
        "X = [\n",
        "    [word_to_index.get(word, word_to_index[\"UNK\"]) for word in sentence]\n",
        "    for sentence in sentences\n",
        "]\n",
        "y = [\n",
        "    [tag_to_index[tag] for tag in tag_list]\n",
        "    for tag_list in tags\n",
        "]"
      ],
      "metadata": {
        "id": "Zcg9DX49265n"
      },
      "execution_count": 407,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 408,
      "metadata": {
        "id": "euzv-VNHROcQ"
      },
      "outputs": [],
      "source": [
        "# split dataset before padding\n",
        "# use last 10% of data as test set\n",
        "split_idx = int(0.9 * len(sentences))  # 90% for training+validation, 10% for test\n",
        "X_train_val, X_test_val = X[:split_idx], X[split_idx:]\n",
        "y_train_val, y_test_val = y[:split_idx], y[split_idx:]\n",
        "# X_test_val, y_test_val: the last 10% of sentences\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_train_val, y_train_val,\n",
        "    test_size=0.2,\n",
        "    random_state=42, shuffle = False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pad sequences after splitting\n",
        "max_len = max(len(s) for s in X_train)  # set max length\n",
        "\n",
        "# padding=\"post\": pad at the end of sequences\n",
        "# value=word_to_index[\"PAD\"]: use the padding token's index for padding\n",
        "\n",
        "X_train = pad_sequences(\n",
        "    X_train, maxlen=max_len, padding=\"post\", value=word_to_index[\"PAD\"]\n",
        ")\n",
        "X_test = pad_sequences(\n",
        "    X_test, maxlen=max_len, padding=\"post\", value=word_to_index[\"PAD\"]\n",
        ")\n",
        "\n",
        "# pad the tag sequences in y_train to match the length of the input sequences\n",
        "y_train = pad_sequences(\n",
        "    y_train, maxlen=max_len, padding=\"post\", value=tag_to_index[\"PAD\"]\n",
        ")\n",
        "y_test = pad_sequences(\n",
        "    y_test, maxlen=max_len, padding=\"post\", value=tag_to_index[\"PAD\"]\n",
        ")"
      ],
      "metadata": {
        "id": "GW_sSqcT20r4"
      },
      "execution_count": 409,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check shapes and indices\n",
        "print(\"\\nFinal shapes:\")\n",
        "X_train_val = pad_sequences(X_train_val, padding='post', maxlen=100)\n",
        "X_test_val = pad_sequences(X_test_val, padding='post', maxlen=100)\n",
        "y_train_val = pad_sequences(y_train_val, padding='post', maxlen=100)\n",
        "y_test_val = pad_sequences(y_test_val, padding='post', maxlen=100)\n",
        "\n",
        "X_train_val = np.array(X_train_val)\n",
        "y_train_val = np.array(y_train_val)\n",
        "X_test_val = np.array(X_test_val)\n",
        "y_test_val = np.array(y_test_val)\n",
        "\n",
        "print(f\"X_train_val: {X_train_val.shape}, y_train_val: {y_train_val.shape}\")\n",
        "print(f\"X_test_val: {X_test_val.shape}, y_test_val: {y_test_val.shape}\")\n",
        "\n",
        "print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
        "print(f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
        "\n",
        "print(\"\\nSample sentence:\", sentences[0])\n",
        "\n",
        "print(\"Mapped indices:\", X_train[0])\n",
        "print(\"Sample tags:\", tags[0])\n",
        "print(\"Mapped tags:\", y_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ip8x-G63EAE",
        "outputId": "bb14320b-3ff5-4c61-9a80-05484fa27c49"
      },
      "execution_count": 410,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final shapes:\n",
            "X_train_val: (2699, 100), y_train_val: (2699, 100)\n",
            "X_test_val: (300, 100), y_test_val: (300, 100)\n",
            "X_train: (2159, 62), y_train: (2159, 62)\n",
            "X_test: (540, 62), y_test: (540, 62)\n",
            "\n",
            "Sample sentence: ['Thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'London', 'to', 'protest', 'the', 'war', 'in', 'Iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'British', 'troops', 'from', 'that', 'country', '.']\n",
            "Mapped indices: [3186 3670 5078  653 7384 4796 3407  561 8688 2447  504 1585 3996 2037\n",
            "  735 2447 1540 3670 2275 4910 1258 7986 2617 1315    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0]\n",
            "Sample tags: ['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O']\n",
            "Mapped tags: [ 1  1  1  1  1  1 10  1  1  1  1  1 10  1  1  1  1  1 11  1  1  1  1  1\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgSVcE6D4BYn"
      },
      "source": [
        "### Build Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bidirectional LSTM-CRF Models for Sequence Tagging"
      ],
      "metadata": {
        "id": "uXaoHXlL-zF2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 411,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5LFGO38WNvr",
        "outputId": "aada3e77-578d-47e5-f922-49b199714b1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-crf in /usr/local/lib/python3.11/dist-packages (0.7.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-crf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 412,
      "metadata": {
        "id": "yoz3V2EXWTFR"
      },
      "outputs": [],
      "source": [
        "from torchcrf import CRF\n",
        "\n",
        "# define the BiLSTM-CRF model class\n",
        "class BiLSTM_CRF(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_tags):\n",
        "        super().__init__()\n",
        "        # embedding layer to convert word indices to word embeddings\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "\n",
        "        # LSTM layer: processes the embedded input sequences\n",
        "        self.lstm = nn.LSTM(\n",
        "            embedding_dim,\n",
        "            hidden_dim // 2,  # bidirectional split\n",
        "            bidirectional=True,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        # fully connected layer: maps the LSTM output to tag predictions\n",
        "        self.fc = nn.Linear(hidden_dim, num_tags)\n",
        "\n",
        "        # CRF layer: performs sequence labeling with a CRF layer on top of LSTM output\n",
        "        self.crf = CRF(num_tags, batch_first=True)\n",
        "\n",
        "    def forward(self, x, tags=None, mask=None):\n",
        "        # forward pass through embedding layer\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        x, _ = self.lstm(x)\n",
        "        # pass the LSTM output through the fully connected layer\n",
        "        emissions = self.fc(x)\n",
        "\n",
        "        if tags is not None:\n",
        "            loss = -self.crf(emissions, tags, mask=mask)\n",
        "            return loss\n",
        "        else:\n",
        "            return self.crf.decode(emissions, mask=mask)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# intialize model with hyperparameter\n",
        "vocab_size = len(word_to_index)  # from preprocessing\n",
        "num_tags = len(tag_to_index)     # from preprocessing\n",
        "model = BiLSTM_CRF(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=100,\n",
        "    hidden_dim=50,\n",
        "    num_tags=num_tags\n",
        ")"
      ],
      "metadata": {
        "id": "CLir6J7z8QNu"
      },
      "execution_count": 413,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvFobOwt4DGO"
      },
      "source": [
        "### Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Prepare Data"
      ],
      "metadata": {
        "id": "eTN7olldzGyU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchcrf import CRF\n",
        "\n",
        "# convert data to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.long)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "\n",
        "# create mask tensor (1 for real tokens, 0 for padding)\n",
        "mask = (X_train_tensor != word_to_index[\"PAD\"]).bool()\n",
        "\n",
        "# create dataset and dataloader\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor, mask)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "5yZbUV6J8gtO"
      },
      "execution_count": 414,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 415,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cYtObGAXt8v",
        "outputId": "64abf1d5-44ae-41f6-f3ae-f8ea5fd13c7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Batch: 000 | Loss: 1779.817\n",
            "Epoch: 01 | Batch: 010 | Loss: 508.060\n",
            "Epoch: 01 | Batch: 020 | Loss: 492.444\n",
            "Epoch: 01 | Batch: 030 | Loss: 476.062\n",
            "Epoch: 01 | Batch: 040 | Loss: 379.368\n",
            "Epoch: 01 | Batch: 050 | Loss: 336.338\n",
            "Epoch: 01 | Batch: 060 | Loss: 440.214\n",
            "\n",
            "Epoch: 01 | Average Loss: 600.885\n",
            "\n",
            "Epoch: 02 | Batch: 000 | Loss: 446.505\n",
            "Epoch: 02 | Batch: 010 | Loss: 318.414\n",
            "Epoch: 02 | Batch: 020 | Loss: 404.325\n",
            "Epoch: 02 | Batch: 030 | Loss: 317.095\n",
            "Epoch: 02 | Batch: 040 | Loss: 326.448\n",
            "Epoch: 02 | Batch: 050 | Loss: 307.499\n",
            "Epoch: 02 | Batch: 060 | Loss: 442.742\n",
            "\n",
            "Epoch: 02 | Average Loss: 387.846\n",
            "\n",
            "Epoch: 03 | Batch: 000 | Loss: 347.380\n",
            "Epoch: 03 | Batch: 010 | Loss: 295.722\n",
            "Epoch: 03 | Batch: 020 | Loss: 370.117\n",
            "Epoch: 03 | Batch: 030 | Loss: 286.520\n",
            "Epoch: 03 | Batch: 040 | Loss: 353.608\n",
            "Epoch: 03 | Batch: 050 | Loss: 271.258\n",
            "Epoch: 03 | Batch: 060 | Loss: 272.825\n",
            "\n",
            "Epoch: 03 | Average Loss: 324.130\n",
            "\n",
            "Epoch: 04 | Batch: 000 | Loss: 297.850\n",
            "Epoch: 04 | Batch: 010 | Loss: 260.399\n",
            "Epoch: 04 | Batch: 020 | Loss: 306.405\n",
            "Epoch: 04 | Batch: 030 | Loss: 217.571\n",
            "Epoch: 04 | Batch: 040 | Loss: 213.039\n",
            "Epoch: 04 | Batch: 050 | Loss: 324.707\n",
            "Epoch: 04 | Batch: 060 | Loss: 278.380\n",
            "\n",
            "Epoch: 04 | Average Loss: 274.059\n",
            "\n",
            "Epoch: 05 | Batch: 000 | Loss: 260.792\n",
            "Epoch: 05 | Batch: 010 | Loss: 281.560\n",
            "Epoch: 05 | Batch: 020 | Loss: 243.707\n",
            "Epoch: 05 | Batch: 030 | Loss: 267.597\n",
            "Epoch: 05 | Batch: 040 | Loss: 213.489\n",
            "Epoch: 05 | Batch: 050 | Loss: 127.758\n",
            "Epoch: 05 | Batch: 060 | Loss: 338.897\n",
            "\n",
            "Epoch: 05 | Average Loss: 234.898\n",
            "\n",
            "Epoch: 06 | Batch: 000 | Loss: 220.450\n",
            "Epoch: 06 | Batch: 010 | Loss: 229.864\n",
            "Epoch: 06 | Batch: 020 | Loss: 273.464\n",
            "Epoch: 06 | Batch: 030 | Loss: 175.952\n",
            "Epoch: 06 | Batch: 040 | Loss: 198.086\n",
            "Epoch: 06 | Batch: 050 | Loss: 202.642\n",
            "Epoch: 06 | Batch: 060 | Loss: 259.957\n",
            "\n",
            "Epoch: 06 | Average Loss: 203.326\n",
            "\n",
            "Epoch: 07 | Batch: 000 | Loss: 221.390\n",
            "Epoch: 07 | Batch: 010 | Loss: 181.173\n",
            "Epoch: 07 | Batch: 020 | Loss: 163.681\n",
            "Epoch: 07 | Batch: 030 | Loss: 194.810\n",
            "Epoch: 07 | Batch: 040 | Loss: 135.361\n",
            "Epoch: 07 | Batch: 050 | Loss: 157.258\n",
            "Epoch: 07 | Batch: 060 | Loss: 166.532\n",
            "\n",
            "Epoch: 07 | Average Loss: 177.015\n",
            "\n",
            "Epoch: 08 | Batch: 000 | Loss: 128.926\n",
            "Epoch: 08 | Batch: 010 | Loss: 140.662\n",
            "Epoch: 08 | Batch: 020 | Loss: 149.839\n",
            "Epoch: 08 | Batch: 030 | Loss: 116.071\n",
            "Epoch: 08 | Batch: 040 | Loss: 136.381\n",
            "Epoch: 08 | Batch: 050 | Loss: 158.099\n",
            "Epoch: 08 | Batch: 060 | Loss: 159.820\n",
            "\n",
            "Epoch: 08 | Average Loss: 154.577\n",
            "\n",
            "Epoch: 09 | Batch: 000 | Loss: 125.332\n",
            "Epoch: 09 | Batch: 010 | Loss: 160.660\n",
            "Epoch: 09 | Batch: 020 | Loss: 138.457\n",
            "Epoch: 09 | Batch: 030 | Loss: 152.157\n",
            "Epoch: 09 | Batch: 040 | Loss: 113.929\n",
            "Epoch: 09 | Batch: 050 | Loss: 125.569\n",
            "Epoch: 09 | Batch: 060 | Loss: 132.811\n",
            "\n",
            "Epoch: 09 | Average Loss: 135.402\n",
            "\n",
            "Epoch: 10 | Batch: 000 | Loss: 95.012\n",
            "Epoch: 10 | Batch: 010 | Loss: 135.608\n",
            "Epoch: 10 | Batch: 020 | Loss: 107.448\n",
            "Epoch: 10 | Batch: 030 | Loss: 81.654\n",
            "Epoch: 10 | Batch: 040 | Loss: 99.986\n",
            "Epoch: 10 | Batch: 050 | Loss: 107.696\n",
            "Epoch: 10 | Batch: 060 | Loss: 131.432\n",
            "\n",
            "Epoch: 10 | Average Loss: 118.739\n",
            "\n",
            "Epoch: 11 | Batch: 000 | Loss: 127.857\n",
            "Epoch: 11 | Batch: 010 | Loss: 148.371\n",
            "Epoch: 11 | Batch: 020 | Loss: 126.954\n",
            "Epoch: 11 | Batch: 030 | Loss: 119.621\n",
            "Epoch: 11 | Batch: 040 | Loss: 114.240\n",
            "Epoch: 11 | Batch: 050 | Loss: 57.741\n",
            "Epoch: 11 | Batch: 060 | Loss: 118.832\n",
            "\n",
            "Epoch: 11 | Average Loss: 104.146\n",
            "\n",
            "Epoch: 12 | Batch: 000 | Loss: 94.733\n",
            "Epoch: 12 | Batch: 010 | Loss: 120.774\n",
            "Epoch: 12 | Batch: 020 | Loss: 85.394\n",
            "Epoch: 12 | Batch: 030 | Loss: 122.437\n",
            "Epoch: 12 | Batch: 040 | Loss: 124.049\n",
            "Epoch: 12 | Batch: 050 | Loss: 80.170\n",
            "Epoch: 12 | Batch: 060 | Loss: 72.991\n",
            "\n",
            "Epoch: 12 | Average Loss: 91.442\n",
            "\n",
            "Epoch: 13 | Batch: 000 | Loss: 54.490\n",
            "Epoch: 13 | Batch: 010 | Loss: 78.795\n",
            "Epoch: 13 | Batch: 020 | Loss: 64.662\n",
            "Epoch: 13 | Batch: 030 | Loss: 83.777\n",
            "Epoch: 13 | Batch: 040 | Loss: 82.404\n",
            "Epoch: 13 | Batch: 050 | Loss: 91.006\n",
            "Epoch: 13 | Batch: 060 | Loss: 82.342\n",
            "\n",
            "Epoch: 13 | Average Loss: 80.165\n",
            "\n",
            "Epoch: 14 | Batch: 000 | Loss: 60.672\n",
            "Epoch: 14 | Batch: 010 | Loss: 74.988\n",
            "Epoch: 14 | Batch: 020 | Loss: 48.912\n",
            "Epoch: 14 | Batch: 030 | Loss: 69.962\n",
            "Epoch: 14 | Batch: 040 | Loss: 70.540\n",
            "Epoch: 14 | Batch: 050 | Loss: 71.644\n",
            "Epoch: 14 | Batch: 060 | Loss: 67.236\n",
            "\n",
            "Epoch: 14 | Average Loss: 70.258\n",
            "\n",
            "Epoch: 15 | Batch: 000 | Loss: 43.986\n",
            "Epoch: 15 | Batch: 010 | Loss: 38.840\n",
            "Epoch: 15 | Batch: 020 | Loss: 49.290\n",
            "Epoch: 15 | Batch: 030 | Loss: 54.484\n",
            "Epoch: 15 | Batch: 040 | Loss: 36.229\n",
            "Epoch: 15 | Batch: 050 | Loss: 53.833\n",
            "Epoch: 15 | Batch: 060 | Loss: 58.614\n",
            "\n",
            "Epoch: 15 | Average Loss: 61.481\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# define optimizer\n",
        "optimizer = optim.RMSprop(model.parameters(), lr=0.001)\n",
        "\n",
        "# training loop\n",
        "num_epochs = 15\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch_idx, (inputs, targets, mask_batch) in enumerate(train_loader):\n",
        "        # zero gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward pass\n",
        "        loss = model(inputs, tags=targets, mask=mask_batch)\n",
        "\n",
        "        # backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # batch progress\n",
        "        if batch_idx % 10 == 0:\n",
        "            print(f'Epoch: {epoch+1:02} | Batch: {batch_idx:03} | Loss: {loss.item():.3f}')\n",
        "\n",
        "    # print epoch statistics\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f'\\nEpoch: {epoch+1:02} | Average Loss: {avg_loss:.3f}\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save model\n",
        "torch.save(model.state_dict(), \"bilstm_crf_ner_model.pt\")"
      ],
      "metadata": {
        "id": "lkjd-o9H6Y03"
      },
      "execution_count": 416,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict function\n",
        "def predict(sentence, model, word_to_index, tag_to_index):\n",
        "    # convert sentence to indices\n",
        "    indexed_sentence = [word_to_index.get(word, word_to_index[\"UNK\"]) for word in sentence]\n",
        "\n",
        "    # convert to tensor and add batch dimension\n",
        "    inputs = torch.tensor([indexed_sentence], dtype=torch.long)\n",
        "    mask = (inputs != word_to_index[\"PAD\"]).bool()\n",
        "\n",
        "    # predice\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        tags = model(inputs, mask=mask)\n",
        "\n",
        "    # convert indices to tags\n",
        "    index_to_tag = {v: k for k, v in tag_to_index.items()}\n",
        "    return [(word, index_to_tag[tag]) for word, tag in zip(sentence, tags[0])]"
      ],
      "metadata": {
        "id": "bS2y7rOm6YW1"
      },
      "execution_count": 417,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 418,
      "metadata": {
        "id": "0JHTWAZlaHbC"
      },
      "outputs": [],
      "source": [
        "# convert test data to tensors\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.long)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# check\n",
        "test_mask = (X_test_tensor != word_to_index[\"PAD\"]).bool()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "gRVnUGex8l1A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Use Precision, Recall and F1 to evaluate model"
      ],
      "metadata": {
        "id": "g_fCi9KdCy3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import necessary metrics for evaluation\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "def evaluate_model(model, dataloader, tag_to_index):\n",
        "    model.eval()  # set the model to evaluation mode\n",
        "    total_correct = 0  # store the count of correctly predicted tokens\n",
        "    total_tokens = 0  # store the total number of tokens\n",
        "\n",
        "    # map from index to tag\n",
        "    index_to_tag = {v: k for k, v in tag_to_index.items()}\n",
        "\n",
        "    # list to store all predictions and true tags\n",
        "    all_preds = []\n",
        "    all_true = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets, mask in dataloader:\n",
        "            # get predictions from the model (list of lists)\n",
        "            preds = model(inputs, mask=mask)\n",
        "\n",
        "            # iterate through each sample in the batch\n",
        "            for i in range(inputs.size(0)):\n",
        "                # mask for current sample to handle padding\n",
        "                sample_mask = mask[i]\n",
        "\n",
        "                # true tags for the current sample (filtered by mask)\n",
        "                true_tags = targets[i][sample_mask]\n",
        "\n",
        "                # predicted tags (converted from list to tensor)\n",
        "                pred_tags = torch.tensor(preds[i][:len(true_tags)], device=inputs.device)\n",
        "\n",
        "                # calculate correct predictions (count matching tags)\n",
        "                total_correct += (pred_tags == true_tags).sum().item()\n",
        "                total_tokens += len(true_tags)\n",
        "\n",
        "                # collect predictions and true tags for precision, recall, and F1 score calculation\n",
        "                all_preds.extend(pred_tags.cpu().numpy())\n",
        "                all_true.extend(true_tags.cpu().numpy())\n",
        "\n",
        "    # calculate token accuracy: correct predictions / total tokens\n",
        "    accuracy = total_correct / total_tokens\n",
        "    print(f\"Token Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    # compute Precision, Recall, and F1 Score with weighted average\n",
        "\n",
        "    precision = precision_score(all_true, all_preds, average='weighted', zero_division=1)\n",
        "    recall = recall_score(all_true, all_preds, average='weighted', zero_division=1)\n",
        "    f1 = f1_score(all_true, all_preds, average='weighted', zero_division=1)\n",
        "\n",
        "    # print the result\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "    return accuracy, precision, recall, f1  # return the calculated metrics\n"
      ],
      "metadata": {
        "id": "2L-6-VBL87iL"
      },
      "execution_count": 419,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 420,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yp_bGyehcGC9",
        "outputId": "01d42aa6-505e-4e7b-d3a1-1c5c50fd6a03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token Accuracy: 0.9204\n",
            "Precision: 0.9146\n",
            "Recall: 0.9204\n",
            "F1 Score: 0.9148\n"
          ]
        }
      ],
      "source": [
        "# ensure test_loader is properly defined:\n",
        "test_loader = DataLoader(\n",
        "    TensorDataset(X_test_tensor, y_test_tensor, test_mask),\n",
        "    batch_size=64\n",
        ")\n",
        "\n",
        "# run evaluation\n",
        "results = evaluate_model(model, test_loader, tag_to_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 421,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRtGujEuivfh",
        "outputId": "502f8d50-3279-47d1-ed9a-ddb47ea968e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Tags:\n",
            "Apple: O\n",
            "Inc.: O\n",
            "is: O\n",
            "based: O\n",
            "in: O\n",
            "California: B-geo\n"
          ]
        }
      ],
      "source": [
        "# check an example\n",
        "test_sentence = [\"Apple\", \"Inc.\", \"is\", \"based\", \"in\", \"California\"]\n",
        "# apply the predict function\n",
        "prediction = predict(test_sentence, model, word_to_index, tag_to_index)\n",
        "\n",
        "# print results\n",
        "print(\"Predicted Tags:\")\n",
        "for word, tag in prediction:\n",
        "    print(f\"{word}: {tag}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}