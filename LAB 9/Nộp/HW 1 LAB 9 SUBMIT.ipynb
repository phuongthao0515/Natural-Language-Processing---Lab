{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11243419,"sourceType":"datasetVersion","datasetId":7024930},{"sourceType":"datasetVersion","sourceId":11256517,"datasetId":7034885}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import Libraries","metadata":{"id":"mswUN254nohl"}},{"cell_type":"code","source":"import tensorflow as tf\nfrom nltk.corpus import stopwords\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, SimpleRNN, Dense, GlobalAveragePooling1D,GRU,LSTM,Bidirectional,Dropout,BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nimport pandas as pd\nimport numpy as np\nimport zipfile\nimport re\nimport string\nimport nltk\nimport torch","metadata":{"id":"65tF4OMEnnBv","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T01:44:41.176899Z","iopub.execute_input":"2025-04-03T01:44:41.177259Z","iopub.status.idle":"2025-04-03T01:44:57.479872Z","shell.execute_reply.started":"2025-04-03T01:44:41.177232Z","shell.execute_reply":"2025-04-03T01:44:57.479216Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## Data Downloading","metadata":{"id":"DrN5IrI5nrFS"}},{"cell_type":"code","source":"# zip_path = \"/content/IMDB Dataset.csv.zip\"\n# extract_to = \"data/\"\n# # Open the zip file\n# with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n#     # Extract specific files\n#     zip_ref.extract(\"IMDB Dataset.csv\", extract_to)","metadata":{"id":"rpEVfrAhozR3"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/dataset-imdb/IMDB Dataset.csv\")\ntrain_df, test_df = train_test_split(train_data, test_size=0.1, random_state=42)","metadata":{"id":"2akOz-h2qt2W","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T01:45:02.954568Z","iopub.execute_input":"2025-04-03T01:45:02.955367Z","iopub.status.idle":"2025-04-03T01:45:04.324119Z","shell.execute_reply.started":"2025-04-03T01:45:02.955329Z","shell.execute_reply":"2025-04-03T01:45:04.323188Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Tải stopwords nếu chưa có\nnltk.download(\"stopwords\")\n\n# Khai báo stopwords\nstop_words = set(stopwords.words(\"english\"))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8copO9053UjV","outputId":"33746701-df03-4a05-f37b-74ce5c25ee54","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T01:45:08.390100Z","iopub.execute_input":"2025-04-03T01:45:08.390378Z","iopub.status.idle":"2025-04-03T01:45:08.506654Z","shell.execute_reply.started":"2025-04-03T01:45:08.390359Z","shell.execute_reply":"2025-04-03T01:45:08.505695Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Unzipping corpora/stopwords.zip.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{"id":"WGxSHk_bnxvq"}},{"cell_type":"code","source":"def preprocess_text(text):\n    text = text.lower()\n    text = re.sub(r\"\\d+\", \"\", text)\n    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n    text = \" \".join([word for word in text.split() if word not in stop_words])\n    text = re.sub(r\"\\s+\", \" \", text).strip()\n    return text\n\ntrain_df[\"review\"] = train_df[\"review\"].apply(preprocess_text)\ntest_df[\"review\"] = test_df[\"review\"].apply(preprocess_text)","metadata":{"id":"d9721i6G3UjW","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T01:45:12.312597Z","iopub.execute_input":"2025-04-03T01:45:12.312916Z","iopub.status.idle":"2025-04-03T01:45:18.572201Z","shell.execute_reply.started":"2025-04-03T01:45:12.312893Z","shell.execute_reply":"2025-04-03T01:45:18.571283Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# separate review and sentiment\nX_train = train_df[\"review\"].values\ny_train = train_df[\"sentiment\"].values\nX_test = test_df[\"review\"].values\ny_test = test_df[\"sentiment\"].values\n\nprint(\"y_train type:\", type(y_train))\nprint(\"Unique values in y_train:\", np.unique(y_train))\n\n# map 1->positive, 0->negative\nif y_train.dtype == 'O':\n    label_mapping = {'positive': 1, 'negative': 0}\n    y_train = np.array([label_mapping[label] for label in y_train], dtype=np.float32)\n    y_test = np.array([label_mapping[label] for label in y_test], dtype=np.float32)\nelse:\n    y_train = y_train.astype(np.float32)\n    y_test = y_test.astype(np.float32)\n\nMAX_WORDS = 10000\nMAX_LEN = 500\n\nEMBEDDING_DIMS = 128\n\n# Tokenize\ntokenizer = Tokenizer(num_words=MAX_WORDS, oov_token=\"<OOV>\")\ntokenizer.fit_on_texts(X_train)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IQqzwVCH3UjW","outputId":"557615be-916d-42a0-ade6-f53e7849cd6c","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T01:45:23.541911Z","iopub.execute_input":"2025-04-03T01:45:23.542217Z","iopub.status.idle":"2025-04-03T01:45:28.015288Z","shell.execute_reply.started":"2025-04-03T01:45:23.542193Z","shell.execute_reply":"2025-04-03T01:45:28.014630Z"}},"outputs":[{"name":"stdout","text":"y_train type: <class 'numpy.ndarray'>\nUnique values in y_train: ['negative' 'positive']\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## Build Model","metadata":{"id":"uiguYT6Lnzo-"}},{"cell_type":"markdown","source":"#### Vanilla RNN Model","metadata":{"id":"BpsGImh3KVeP"}},{"cell_type":"code","source":"# Vanilla RNN model\ndef create_rnn_model():\n    model = Sequential([\n        Embedding(input_dim=MAX_WORDS, output_dim=EMBEDDING_DIMS, mask_zero=True),  # mask_zero=True\n        SimpleRNN(128, dropout=0.2, recurrent_dropout=0.2, return_sequences=False),  # return_sequences=False -> output 2D\n        Dense(1, activation='sigmoid')\n    ])\n    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n    return model","metadata":{"id":"kJ3_ExCopnMR","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T01:45:40.084469Z","iopub.execute_input":"2025-04-03T01:45:40.084807Z","iopub.status.idle":"2025-04-03T01:45:40.089062Z","shell.execute_reply.started":"2025-04-03T01:45:40.084781Z","shell.execute_reply":"2025-04-03T01:45:40.088216Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)","metadata":{"id":"WfIbHpM1o4x1","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T01:45:44.502478Z","iopub.execute_input":"2025-04-03T01:45:44.502825Z","iopub.status.idle":"2025-04-03T01:45:44.506682Z","shell.execute_reply.started":"2025-04-03T01:45:44.502797Z","shell.execute_reply":"2025-04-03T01:45:44.505615Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"#### GRU Model","metadata":{"id":"peN4Yxi5KYRp"}},{"cell_type":"code","source":"\n# from tensorflow.keras.layers import GRU, Dense, Embedding, Bidirectional, BatchNormalization, Dropout\n# from tensorflow.keras.models import Sequential\n# from tensorflow.keras.optimizers import Adam\n# from tensorflow.keras.regularizers import l2\n\n# def create_gru_model():\n#     model = Sequential([\n#         # Embedding Layer với mask_zero để xử lý padding\n#         Embedding(\n#             input_dim=MAX_WORDS,\n#             output_dim=EMBEDDING_DIMS,\n#             input_length=MAX_LEN,\n#             mask_zero=True\n#         ),\n\n#         # Stacked Bidirectional GRU Layers\n#         GRU(\n#             128,\n#             return_sequences=True,\n#             dropout=0.3,          # Dropout cho đầu vào\n#             recurrent_dropout=0.2, # Dropout cho recurrent state\n#             kernel_regularizer=l2(1e-4)\n#         ),\n#         BatchNormalization(),\n\n#         GRU(\n#             64,\n#             return_sequences=False, # Layer cuối không cần return sequences\n#             dropout=0.2,\n#             recurrent_dropout=0.1\n#         ),\n#         Dropout(0.3),\n\n#         # Hidden Layers với regularization\n#         Dense(32, activation='relu', kernel_regularizer=l2(1e-4)),\n#         BatchNormalization(),\n#         Dropout(0.2),\n\n#         # Output Layer\n#         Dense(1, activation='sigmoid')\n#     ])\n\n#     # optimize\n#     optimizer = Adam(\n#         learning_rate=1e-3,\n#         clipnorm=1.0  # avoid exploding gradients\n#     )\n\n#     model.compile(\n#         optimizer=Adam(learning_rate=1e-4),\n#         loss='binary_crossentropy',\n#         metrics=['accuracy']\n#     )\n#     return model\nfrom tensorflow.keras.layers import GRU, Dense, Embedding, Dropout\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.optimizers import Adam\n\ndef create_gru_model():\n    model = Sequential([\n        Embedding(\n            input_dim=MAX_WORDS,\n            output_dim=EMBEDDING_DIMS,\n            input_length=MAX_LEN,\n            mask_zero=True\n        ),\n\n        # Dropout cho embedding layer\n        Dropout(0.3),\n\n        # GRU Layer 1\n        GRU(\n            128,\n            return_sequences=True,\n            dropout=0.3,\n            recurrent_dropout=0.2,\n            kernel_regularizer=l2(1e-4)\n        ),\n        # GRU Layer 2\n        GRU(\n            64,\n            dropout=0.2,\n            recurrent_dropout=0.1\n        ),\n        # Hidden Layer với regularization\n        Dense(32, activation='relu', kernel_regularizer=l2(1e-4)),\n        Dropout(0.2),\n        Dense(1, activation='sigmoid')\n    ])\n    model.compile(\n        optimizer=Adam(learning_rate=1e-4),\n        loss='binary_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n","metadata":{"id":"fCO7MXDuKGat"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### LSTM Model","metadata":{"id":"AdcnRn5SpAYr"}},{"cell_type":"code","source":"# LSTM model\nearly_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n\nfrom tensorflow.keras.layers import Bidirectional, LSTM, Dropout, BatchNormalization, Dense\nfrom tensorflow.keras.regularizers import l2\n\ndef create_lstm_model():\n    model = Sequential([\n        # embedding\n        Embedding(input_dim=MAX_WORDS, output_dim=64, mask_zero=True),\n\n        # optimized bidirectional LSTM\n        Bidirectional(LSTM(32, return_sequences=True)),\n        BatchNormalization(),\n\n        Bidirectional(LSTM(16)),\n        Dropout(0.1),\n\n        # dense layers with reduced regularization\n        Dense(16, activation=\"relu\"),\n        BatchNormalization(),\n\n        # Output layer\n        Dense(1, activation=\"sigmoid\")\n    ])\n\n    model.compile(\n        optimizer=Adam(learning_rate=1e-4),\n        loss='binary_crossentropy',\n        metrics=['accuracy']\n    )\n    return model","metadata":{"id":"EMGKH8SIKQKC","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T01:52:08.957374Z","iopub.execute_input":"2025-04-03T01:52:08.957762Z","iopub.status.idle":"2025-04-03T01:52:08.965967Z","shell.execute_reply.started":"2025-04-03T01:52:08.957733Z","shell.execute_reply":"2025-04-03T01:52:08.965077Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## Train Model","metadata":{"id":"NtJgiPrHpPTw"}},{"cell_type":"markdown","source":"#### Train Vanilla RNN Model","metadata":{"id":"oDj4NdgSphCR"}},{"cell_type":"code","source":"# convert text data to sequences of integers using the tokenizer\nX_train_seq = tokenizer.texts_to_sequences(X_train)\nX_test_seq = tokenizer.texts_to_sequences(X_test)\n\n# padding sequence\nX_train_pad = pad_sequences(X_train_seq, maxlen=MAX_LEN, padding=\"post\")\nX_test_pad = pad_sequences(X_test_seq, maxlen=MAX_LEN, padding=\"post\")\n","metadata":{"id":"dJwoU1zVqCx9","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T01:45:52.681353Z","iopub.execute_input":"2025-04-03T01:45:52.681718Z","iopub.status.idle":"2025-04-03T01:45:56.166806Z","shell.execute_reply.started":"2025-04-03T01:45:52.681691Z","shell.execute_reply":"2025-04-03T01:45:56.165859Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# train Vanilla RNN model\nrnn_model = create_rnn_model()\nX_train_tensor = np.array(X_train_pad, dtype=np.int32)\ny_train_tensor = np.array(y_train, dtype=np.float32)\nX_test_tensor = np.array(X_test_pad, dtype=np.int32)\ny_test_tensor = np.array(y_test, dtype=np.float32)\n\n# train model\nhistory_rnn = rnn_model.fit(\n    X_train_tensor, y_train_tensor,\n    validation_data=(X_test_tensor, y_test_tensor),\n    epochs=10, batch_size=64\n)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ysKbSojdaMOy","outputId":"e546ee95-ce6c-42f9-bd7f-5265c9a8d8de","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T01:46:02.781893Z","iopub.execute_input":"2025-04-03T01:46:02.782205Z","iopub.status.idle":"2025-04-03T01:51:49.279516Z","shell.execute_reply.started":"2025-04-03T01:46:02.782181Z","shell.execute_reply":"2025-04-03T01:51:49.278647Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 52ms/step - accuracy: 0.5147 - loss: 0.7024 - val_accuracy: 0.6222 - val_loss: 0.6558\nEpoch 2/10\n\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 48ms/step - accuracy: 0.6309 - loss: 0.6306 - val_accuracy: 0.7276 - val_loss: 0.5360\nEpoch 3/10\n\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 48ms/step - accuracy: 0.7513 - loss: 0.5041 - val_accuracy: 0.7108 - val_loss: 0.5507\nEpoch 4/10\n\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 48ms/step - accuracy: 0.7656 - loss: 0.4848 - val_accuracy: 0.7066 - val_loss: 0.5634\nEpoch 5/10\n\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 48ms/step - accuracy: 0.7752 - loss: 0.4731 - val_accuracy: 0.7874 - val_loss: 0.4935\nEpoch 6/10\n\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 48ms/step - accuracy: 0.8401 - loss: 0.3723 - val_accuracy: 0.7828 - val_loss: 0.4761\nEpoch 7/10\n\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 48ms/step - accuracy: 0.8446 - loss: 0.3675 - val_accuracy: 0.6920 - val_loss: 0.5859\nEpoch 8/10\n\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 48ms/step - accuracy: 0.7776 - loss: 0.4619 - val_accuracy: 0.7518 - val_loss: 0.5320\nEpoch 9/10\n\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 48ms/step - accuracy: 0.8234 - loss: 0.3946 - val_accuracy: 0.7624 - val_loss: 0.5119\nEpoch 10/10\n\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 48ms/step - accuracy: 0.8213 - loss: 0.4015 - val_accuracy: 0.7708 - val_loss: 0.4965\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"#### Train GRU Model","metadata":{"id":"KIJP9Mw-pL2X"}},{"cell_type":"code","source":"X_train_seq = tokenizer.texts_to_sequences(X_train)\nX_test_seq = tokenizer.texts_to_sequences(X_test)\n\n# padding\nX_train_pad = pad_sequences(X_train_seq, maxlen=MAX_LEN, padding=\"post\")\nX_test_pad = pad_sequences(X_test_seq, maxlen=MAX_LEN, padding=\"post\")\n","metadata":{"id":"buL9hbPfNpNF"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# train GRU model\nearly_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\ngru_model = create_gru_model()\nhistory_gru = gru_model.fit(X_train_pad, y_train, validation_data=(X_test_pad, y_test),\n                            epochs=5, batch_size=128, callbacks=[early_stopping])","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"ZwCNr6KzKM5J","outputId":"3dac5d4f-d710-4765-f392-b37b7d15f312"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m817s\u001b[0m 2s/step - accuracy: 0.5560 - loss: 0.6965 - val_accuracy: 0.8276 - val_loss: 0.4052\n","Epoch 2/5\n","\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m867s\u001b[0m 2s/step - accuracy: 0.8353 - loss: 0.4059 - val_accuracy: 0.8600 - val_loss: 0.3388\n","Epoch 3/5\n","\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m810s\u001b[0m 2s/step - accuracy: 0.8714 - loss: 0.3312 - val_accuracy: 0.8772 - val_loss: 0.3064\n","Epoch 4/5\n","\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m862s\u001b[0m 2s/step - accuracy: 0.8860 - loss: 0.3029 - val_accuracy: 0.8842 - val_loss: 0.2923\n","Epoch 5/5\n","\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m864s\u001b[0m 2s/step - accuracy: 0.8987 - loss: 0.2749 - val_accuracy: 0.8858 - val_loss: 0.2842\n"]}],"execution_count":null},{"cell_type":"code","source":"# Define tokenizer (adjust num_words if needed)\ntokenizer = Tokenizer(num_words=MAX_WORDS, oov_token=\"<OOV>\")\ntokenizer.fit_on_texts(X_train)  # Fit tokenizer on training data\n\n# Convert text to sequences\nX_train_seq = tokenizer.texts_to_sequences(X_train)\nX_test_seq = tokenizer.texts_to_sequences(X_test)\n\n# pad the sequences\nX_train_pad = pad_sequences(X_train_seq, maxlen=MAX_LEN, padding='post')\nX_test_pad = pad_sequences(X_test_seq, maxlen=MAX_LEN, padding='post')","metadata":{"colab":{"background_save":true},"id":"y_sVC6OUot7r","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T02:15:52.488739Z","iopub.execute_input":"2025-04-03T02:15:52.489043Z","iopub.status.idle":"2025-04-03T02:16:00.493151Z","shell.execute_reply.started":"2025-04-03T02:15:52.489023Z","shell.execute_reply":"2025-04-03T02:16:00.492370Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Train LSTM model\nlstm_model = create_lstm_model()\nhistory_lstm = lstm_model.fit(X_train_pad, y_train, validation_data=(X_test_pad, y_test),\n                              epochs=5, batch_size=64, callbacks=[early_stopping])","metadata":{"id":"LModeSp7KOtp","colab":{"base_uri":"https://localhost:8080/"},"outputId":"46a1c515-b479-4542-c2df-43aa56055aa5","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T02:16:09.619128Z","iopub.execute_input":"2025-04-03T02:16:09.619403Z","iopub.status.idle":"2025-04-03T02:18:25.357513Z","shell.execute_reply.started":"2025-04-03T02:16:09.619383Z","shell.execute_reply":"2025-04-03T02:18:25.356808Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/5\n\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 62ms/step - accuracy: 0.5840 - loss: 0.7170 - val_accuracy: 0.8044 - val_loss: 0.4370\nEpoch 2/5\n\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 62ms/step - accuracy: 0.8422 - loss: 0.3611 - val_accuracy: 0.8642 - val_loss: 0.3137\nEpoch 3/5\n\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 62ms/step - accuracy: 0.9099 - loss: 0.2302 - val_accuracy: 0.8828 - val_loss: 0.2741\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"### Plot results","metadata":{"id":"_KTZ04s4Kcv0"}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Plot accuracy\nplt.plot(history_rnn.history['val_accuracy'], label=\"Vanilla RNN\")\nplt.plot(history_gru.history['val_accuracy'], label=\"GRU\")\nplt.plot(history_lstm.history['val_accuracy'], label=\"LSTM\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Validation Accuracy\")\nplt.legend()\nplt.title(\"Model Accuracy Comparison\")\nplt.show()\n","metadata":{"id":"ud3WSBKoaQJD"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef plot_accuracy(history):\n    \"\"\"\n    Plots training and validation accuracy over epochs.\n\n    Parameters:\n    history (dict or keras.callbacks.History):\n        A dictionary or Keras History object containing 'accuracy' and 'val_accuracy'.\n    \"\"\"\n    if hasattr(history, 'history'):  # If it's a Keras History object, extract history\n        history = history.history\n\n    epochs = range(1, len(history['accuracy']) + 1)\n\n    plt.figure(figsize=(8, 5))\n    plt.plot(epochs, history['accuracy'], label='Training Accuracy', marker='o')\n    plt.plot(epochs, history['val_accuracy'], label='Validation Accuracy', marker='s')\n\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.title('Training vs Validation Accuracy')\n    plt.legend()\n    plt.grid(True)\n    plt.show()","metadata":{"id":"ewxBPo623UjY"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_accuracy(lstm_model.history)","metadata":{"id":"0oldlZej3UjY"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_accuracy(rnn_model.history)","metadata":{"id":"r6TAk-pK3UjY"},"outputs":[],"execution_count":null}]}