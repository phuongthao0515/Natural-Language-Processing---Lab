{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6DzHmhff_5jf"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import string\n",
        "import math\n",
        "import re\n",
        "import contractions\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "touIVuNhVBDB",
        "outputId": "a0e44e5f-6aa6-4cb2-c994-febb5555f7e6"
      },
      "outputs": [],
      "source": [
        "pip install contractions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKZubjDDcgZ4",
        "outputId": "265ffd58-5cab-4af7-b4f5-4a3f4602b3c7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJAJ6K8pLsa-"
      },
      "source": [
        "## DATA DOWNLOADING\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "wDKGX9UMcjTB"
      },
      "outputs": [],
      "source": [
        "file_path = \"tedtalk.txt\"\n",
        "with open(file_path, 'r', encoding = 'utf-8') as f:\n",
        "  data = f.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_U1WXRTiLGE"
      },
      "source": [
        "## PREPROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "hINVU1A8dDcI"
      },
      "outputs": [],
      "source": [
        "# preprocessing data\n",
        "def preprocess_text(data):\n",
        "  # convert to lowercase\n",
        "  text = data.lower()\n",
        "  # separate text into sentences\n",
        "  sentences = nltk.sent_tokenize(text)\n",
        "  processed_stc = []\n",
        "\n",
        "  for sentence in sentences:\n",
        "    # expand contractions\n",
        "    sentence = contractions.fix(sentence)\n",
        "    # remove punctuation except ., !, ?\n",
        "    sentence = re.sub(r\"[^a-z0-9.!?]\", \" \", sentence)\n",
        "    # remove multiple spaces\n",
        "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "    # tokenize using nltk\n",
        "    tokens = nltk.word_tokenize(sentence)\n",
        "    # add <s> at the beginning and </s> at the end for sentence boundary\n",
        "    processed_stc.append([\"<s>\"] + tokens + [\"</s>\"])\n",
        "\n",
        "  return processed_stc\n",
        "\n",
        "# processed_data\n",
        "processed_data = preprocess_text(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7PRz981h--A",
        "outputId": "77b16827-00eb-4a01-edae-f970847dd380"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['<s>', 'thank', 'you', 'so', 'much', 'chris', '.', '</s>']\n",
            "['<s>', 'and', 'it', 'is', 'truly', 'a', 'great', 'honor', 'to', 'have', 'the', 'opportunity', 'to', 'come', 'to', 'this', 'stage', 'twice', 'i', 'am', 'extremely', 'grateful', '.', '</s>']\n",
            "['<s>', 'i', 'have', 'been', 'blown', 'away', 'by', 'this', 'conference', 'and', 'i', 'want', 'to', 'thank', 'all', 'of', 'you', 'for', 'the', 'many', 'nice', 'comments', 'about', 'what', 'i', 'had', 'to', 'say', 'the', 'other', 'night', '.', '</s>']\n",
            "['<s>', 'and', 'i', 'say', 'that', 'sincerely', 'partly', 'because', 'mock', 'sob', 'i', 'need', 'that', '.', '</s>']\n",
            "['<s>', 'laughter', 'put', 'yourselves', 'in', 'my', 'position', '.', '</s>']\n"
          ]
        }
      ],
      "source": [
        "# test first 5 sentence in processed_data\n",
        "for sentence in processed_data[:5]:\n",
        "  print(sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ziXVFOeiZg8"
      },
      "source": [
        "## a. Build a language model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "vpFzIhEYia1I"
      },
      "outputs": [],
      "source": [
        "# create n-grams from processed tokens\n",
        "def get_ngrams(tokens, n):\n",
        "  ngrams = [tuple(tokens[i:i+n]) for i in range(len(tokens)-n+1)]\n",
        "  return ngrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "r_ksm-6wwVuf"
      },
      "outputs": [],
      "source": [
        "# laplace_smoothing formula\n",
        "def laplace_smoothing(ngram_counts, context_counts, vocab_size, n):\n",
        "    probs = {}\n",
        "    for ngram in ngram_counts:\n",
        "        # unigram: n=1\n",
        "        if n == 1:\n",
        "            # Unigram: N + V\n",
        "            total_tokens = context_counts  # context_counts is total_tokens if n=1\n",
        "            # calculate the laplace smoothing formula\n",
        "            prob = (ngram_counts.get(ngram,0) + 1) / (total_tokens + vocab_size)\n",
        "        else:\n",
        "            # count(context) + V\n",
        "            # extract the context (n-1) from the ngram\n",
        "            context = ngram[:-1]\n",
        "            # get the count of the context from context_counts\n",
        "            count_context = context_counts.get(context, 0)\n",
        "            # calculate the laplace smoothing formula\n",
        "            prob = (ngram_counts.get(ngram,0) + 1) / (count_context + vocab_size)\n",
        "        # store in the prob dictionary\n",
        "        probs[ngram] = prob\n",
        "    return probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "zAnKyYJj4i2B"
      },
      "outputs": [],
      "source": [
        "# models based on ngram with n (n=1,2,3)\n",
        "def train_ngram_model (tokens, n):\n",
        "  # generate n-grams from the processed train data\n",
        "  ngrams = get_ngrams(tokens, n)\n",
        "  # count the frequency of each n-gram in train data using the Counter class\n",
        "  ngram_counts = Counter(ngrams)\n",
        "\n",
        "  # If n is 1 (unigram), calculate the total number of tokens\n",
        "  if n==1:\n",
        "    context_counts = sum(ngram_counts.values())\n",
        "  else:\n",
        "    # with n>1: generate (n-1)-grams (context) from the processed train data\n",
        "    context_ngrams = get_ngrams(tokens, n-1)\n",
        "    # count the frequency of each (n-1)-gram (context) using the Counter class\n",
        "    context_counts = Counter(context_ngrams)\n",
        "  # calculate the vocab size (number of unique tokens in token list)\n",
        "  vocab_size = len(set(tokens))\n",
        "  # return the n-gram counts, context counts, and vocabulary size\n",
        "  return ngram_counts, context_counts, vocab_size\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qWHwKJmJp9k"
      },
      "source": [
        "### Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "zfewwTxm5B-7"
      },
      "outputs": [],
      "source": [
        "# flatten the data\n",
        "flat_data = [word for sentence in processed_data for word in sentence]\n",
        "\n",
        "# unigram model: n=1\n",
        "# trains a unigram model and calculates the smoothed probabilities for unigrams\n",
        "uni_ngram_counts, uni_context_counts, vocab_size = train_ngram_model(flat_data, 1)\n",
        "unigram_prob = laplace_smoothing(uni_ngram_counts, uni_context_counts, vocab_size, 1)\n",
        "\n",
        "# bigram model: n=2\n",
        "# trains a bigram model and calculates the smoothed probabilities for bigrams\n",
        "bi_ngram_counts, bi_context_counts, vocab_size = train_ngram_model(flat_data, 2)\n",
        "bigram_prob = laplace_smoothing(bi_ngram_counts, bi_context_counts, vocab_size, 2)\n",
        "\n",
        "# trigram model: n=3\n",
        "# trains a trigram model and calculates the smoothed probabilities for trigrams\n",
        "tri_ngram_counts, tri_context_counts, vocab_size = train_ngram_model(flat_data, 3)\n",
        "trigram_prob = laplace_smoothing(tri_ngram_counts, tri_context_counts, vocab_size, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMPVveP-8Ndy"
      },
      "source": [
        "## b. Calculate the probability of a sentence and compute the Perplexity of a sentence based on 1-gram, 2-gram, and 3-gram models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "if3tm8_f8Rdx"
      },
      "outputs": [],
      "source": [
        "# calculate the probability of a sentence\n",
        "def calculate_sentence_prob(sentence, ngram_probs,context_counts, n, vocab_size):\n",
        "  prob = 1.0\n",
        "  for i in range(len(sentence)-n+1):\n",
        "    # extract the n-gram from the sentence\n",
        "    ngram = tuple(sentence[i:i+n])\n",
        "    # process if tokens are not in tokens list (train data)\n",
        "    if n == 1:\n",
        "        total_tokens = context_counts  # context_counts for n=1\n",
        "        count_context = total_tokens\n",
        "    else:\n",
        "        context = ngram[:-1]\n",
        "        count_context = context_counts.get(context, 0) # others n-grams\n",
        "\n",
        "    if ngram in ngram_probs:\n",
        "      prob *= ngram_probs[ngram] # multiply the probability by the n-gram's probability find in the prob dictionary of train data\n",
        "    else:\n",
        "      prob *= 1/(count_context + vocab_size) # apply Laplace smoothing if the n-gram is not found, count_ngrams = 0\n",
        "  return prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "HJjSgxy78Tv5"
      },
      "outputs": [],
      "source": [
        "# perplexity\n",
        "def perplexity(sentence, ngram_probs,context_counts, n,vocab_size):\n",
        "  prob = calculate_sentence_prob(sentence, ngram_probs,context_counts, n,vocab_size)\n",
        "  N = len(sentence) # the length of input sentence\n",
        "  # calculates the perplexity from the prob\n",
        "  return math.pow(prob, -1/N)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-qkuSfr-ErW",
        "outputId": "64d37173-7666-428b-eb24-a116ff55326c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['<s>', 'i', 'want', 'to', 'go', 'to', 'school', '</s>']\n",
            "69371\n",
            "1-gram probability: 1.3281553436964184e-17, 1-gram perplexity: 128.70454711879646\n",
            "2-gram probability: 5.088333895898929e-16, 2-gram perplexity: 81.59772486118717\n",
            "3-gram probability: 1.8867762518029128e-16, 3-gram perplexity: 92.37085208501146\n"
          ]
        }
      ],
      "source": [
        "# calculate the probability and perplexity based on 1-gram, 2-gram and 3-gram models\n",
        "ex = \"I want to go to school\"\n",
        "ex = preprocess_text(ex)\n",
        "ex = [word for sentence in ex for word in sentence]\n",
        "print(ex)\n",
        "\n",
        "vocab_size = len(set(flat_data))  # size of vocabulary\n",
        "print(vocab_size)\n",
        "# 1-gram\n",
        "uni_prob = calculate_sentence_prob(ex, unigram_prob,uni_context_counts,1,vocab_size)\n",
        "uni_perplexity = perplexity(ex, unigram_prob,uni_context_counts, 1,vocab_size)\n",
        "\n",
        "# 2-gram\n",
        "bi_prob = calculate_sentence_prob(ex, bigram_prob,bi_context_counts,2,vocab_size)\n",
        "bi_perplexity = perplexity(ex, bigram_prob,bi_context_counts, 2, vocab_size)\n",
        "\n",
        "# 3-gram\n",
        "tri_prob = calculate_sentence_prob(ex, trigram_prob,tri_context_counts,3,vocab_size)\n",
        "tri_perplexity = perplexity(ex, trigram_prob,tri_context_counts, 3, vocab_size)\n",
        "\n",
        "print(f\"1-gram probability: {uni_prob}, 1-gram perplexity: {uni_perplexity}\")\n",
        "print(f\"2-gram probability: {bi_prob}, 2-gram perplexity: {bi_perplexity}\")\n",
        "print(f\"3-gram probability: {tri_prob}, 3-gram perplexity: {tri_perplexity}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bZ3mASdsnqd"
      },
      "source": [
        "### c. Analyze the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### An example with spelling errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M632NM8IVL70",
        "outputId": "bf205578-c8a7-493d-bf62-354651774021"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "spelling error sentence:  ['<s>', 'i', 'watn', 'to', 'conect', 'with', 'you', '</s>']\n",
            "correct spelling sentence:  ['<s>', 'i', 'want', 'to', 'connect', 'with', 'you', '</s>']\n",
            "1-gram spelling error sentence probability: 6.929980831167371e-25, spelling error sentence perplexity: 1046.9079453620172\n",
            "1-gram correct spelling sentence probability: 4.4441343372001544e-18, incorrect sentence perplexity: 147.57969304568198\n",
            "2-gram spelling error sentence probability: 9.552223057173248e-30, spelling error sentence perplexity: 4241.182327565566\n",
            "2-gram correct spelling sentence probability: 7.60112745573867e-18, incorrect sentence perplexity: 138.0035467647108\n",
            "3-gram spelling error sentence probability: 6.263621601062258e-30, spelling error sentence perplexity: 4470.919093292865\n",
            "3-gram correct spelling sentence probability: 296.7808113242535, incorrect sentence perplexity: 296.7808113242535\n"
          ]
        }
      ],
      "source": [
        "# test an example with spelling errors\n",
        "spelling_error_sentence = \"i watn to conect with you\"\n",
        "correct_spelling_sentence = \"i want to connect with you\"\n",
        "# preprocessing\n",
        "spelling_error_sentence = preprocess_text(spelling_error_sentence)\n",
        "spelling_error_sentence = [word for sentence in spelling_error_sentence for word in sentence]\n",
        "print(\"spelling error sentence: \", spelling_error_sentence)\n",
        "\n",
        "correct_spelling_sentence = preprocess_text(correct_spelling_sentence)\n",
        "correct_spelling_sentence = [word for sentence in correct_spelling_sentence for word in sentence]\n",
        "print(\"correct spelling sentence: \", correct_spelling_sentence)\n",
        "\n",
        "# calculate the probability and perplexity\n",
        "# 1-gram\n",
        "uni_spelling_error_sentence_prob = calculate_sentence_prob(spelling_error_sentence, unigram_prob, uni_context_counts, 1, vocab_size)\n",
        "uni_spelling_error_sentence_perplexity = perplexity(spelling_error_sentence, unigram_prob, uni_context_counts,1,vocab_size)\n",
        "\n",
        "uni_correct_spelling_sentence_prob = calculate_sentence_prob(correct_spelling_sentence, unigram_prob,uni_context_counts,1,vocab_size)\n",
        "uni_correct_spelling_sentence_perplexity = perplexity(correct_spelling_sentence, unigram_prob,uni_context_counts, 1, vocab_size)\n",
        "\n",
        "# print the results\n",
        "# 1-gram\n",
        "print(f\"1-gram spelling error sentence probability: {uni_spelling_error_sentence_prob}, spelling error sentence perplexity: {uni_spelling_error_sentence_perplexity}\")\n",
        "print(f\"1-gram correct spelling sentence probability: {uni_correct_spelling_sentence_prob}, incorrect sentence perplexity: {uni_correct_spelling_sentence_perplexity}\")\n",
        "\n",
        "# 2-gram\n",
        "bi_spelling_error_sentence_prob = calculate_sentence_prob(spelling_error_sentence, bigram_prob,bi_context_counts,2, vocab_size)\n",
        "bi_spelling_error_sentence_perplexity = perplexity(spelling_error_sentence, bigram_prob, bi_context_counts, 2, vocab_size)\n",
        "\n",
        "bi_correct_spelling_sentence_prob = calculate_sentence_prob(correct_spelling_sentence, bigram_prob,bi_context_counts,2, vocab_size)\n",
        "bi_correct_spelling_sentence_perplexity = perplexity(correct_spelling_sentence, bigram_prob,bi_context_counts, 2, vocab_size)\n",
        "\n",
        "# print the results\n",
        "# 2-gram\n",
        "print(f\"2-gram spelling error sentence probability: {bi_spelling_error_sentence_prob}, spelling error sentence perplexity: {bi_spelling_error_sentence_perplexity}\")\n",
        "print(f\"2-gram correct spelling sentence probability: {bi_correct_spelling_sentence_prob}, incorrect sentence perplexity: {bi_correct_spelling_sentence_perplexity}\")\n",
        "\n",
        "# 3-gram\n",
        "tri_spelling_error_sentence_prob = calculate_sentence_prob(spelling_error_sentence, trigram_prob,tri_context_counts,3, vocab_size)\n",
        "tri_spelling_error_sentence_perplexity = perplexity(spelling_error_sentence, trigram_prob,tri_context_counts, 3, vocab_size)\n",
        "\n",
        "tri_correct_spelling_sentence_prob = calculate_sentence_prob(correct_spelling_sentence, trigram_prob,tri_context_counts,3, vocab_size)\n",
        "tri_correct_spelling_sentence_prob = perplexity(correct_spelling_sentence, trigram_prob,tri_context_counts, 3, vocab_size)\n",
        "\n",
        "# print the results\n",
        "# 3-gram\n",
        "print(f\"3-gram spelling error sentence probability: {tri_spelling_error_sentence_prob}, spelling error sentence perplexity: {tri_spelling_error_sentence_perplexity}\")\n",
        "print(f\"3-gram correct spelling sentence probability: {tri_correct_spelling_sentence_prob}, incorrect sentence perplexity: {tri_correct_spelling_sentence_prob}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8b1go5-YeMt"
      },
      "source": [
        "### Conclusion:\n",
        "- Probability:\n",
        "The correct spelling sentence has a significantly higher probability than the spelling error sentence.\n",
        "- Perplexity:\n",
        "The perplexity of the spelling error sentence is significantly higher than that of the correctly spelled sentence, indicating that the model finds the misspelled sentence much more difficult to predict.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test with two similar sentences, where one has the correct word order and the other has an incorrect word order"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuZE_BbmS2sC",
        "outputId": "9909d4c8-24fb-4eb5-d919-485ab7343d25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "correct sentence:  ['<s>', 'i', 'want', 'to', 'speak', 'at', 'ted', 'talk', '.', '</s>']\n",
            "incorrect sentence:  ['<s>', 'i', 'to', 'want', 'at', 'speak', 'talk', 'ted', '.', '</s>']\n",
            "1-gram correct sentence probability: 1.6500270200665751e-24, correct sentence perplexity: 238.91911336091727\n",
            "1-gram incorrect sentence probability: 1.6500270200665751e-24, incorrect sentence perplexity: 238.91911336091727\n",
            "2-gram correct sentence probability: 7.018851426172904e-19, correct sentence perplexity: 65.36923387132117\n",
            "2-gram incorrect sentence probability: 2.8407779798543517e-31, incorrect sentence perplexity: 1134.1128486744187\n",
            "3-gram correct sentence probability: 8.270165684663899e-26, correct sentence perplexity: 322.2912975783582\n",
            "3-gram incorrect sentence probability: 2.0222862409738123e-37, incorrect sentence perplexity: 4671.06313454491\n"
          ]
        }
      ],
      "source": [
        "# test two similar sentences, where one has the correct word order and the other has an incorrect word order\n",
        "correct_sentence = \"I want to speak at ted talk.\"\n",
        "incorrect_sentence = \"I to want at speak talk ted.\"\n",
        "\n",
        "# preprocessing\n",
        "correct_sentence = preprocess_text(correct_sentence)\n",
        "correct_sentence = [word for sentence in correct_sentence for word in sentence]\n",
        "print(\"correct sentence: \", correct_sentence)\n",
        "\n",
        "incorrect_sentence = preprocess_text(incorrect_sentence)\n",
        "incorrect_sentence = [word for sentence in incorrect_sentence for word in sentence]\n",
        "print(\"incorrect sentence: \", incorrect_sentence)\n",
        "\n",
        "# calculate the probability and perplexity\n",
        "# 1-gram\n",
        "correct_uni_prob = calculate_sentence_prob(correct_sentence, unigram_prob, uni_context_counts, 1, vocab_size)\n",
        "correct_uni_perplexity = perplexity(correct_sentence, unigram_prob, uni_context_counts,1,vocab_size)\n",
        "\n",
        "wrong_uni_prob = calculate_sentence_prob(incorrect_sentence, unigram_prob,uni_context_counts,1,vocab_size)\n",
        "wrong_uni_perplexity = perplexity(incorrect_sentence, unigram_prob,uni_context_counts, 1, vocab_size)\n",
        "\n",
        "# 2-gram\n",
        "correct_bi_prob = calculate_sentence_prob(correct_sentence, bigram_prob,bi_context_counts,2, vocab_size)\n",
        "correct_bi_perplexity = perplexity(correct_sentence, bigram_prob, bi_context_counts, 2, vocab_size)\n",
        "\n",
        "wrong_bi_prob = calculate_sentence_prob(incorrect_sentence, bigram_prob,bi_context_counts,2, vocab_size)\n",
        "wrong_bi_perplexity = perplexity(incorrect_sentence, bigram_prob,bi_context_counts, 2, vocab_size)\n",
        "\n",
        "# 3-gram\n",
        "correct_tri_prob = calculate_sentence_prob(correct_sentence, trigram_prob,tri_context_counts,3, vocab_size)\n",
        "correct_tri_perplexity = perplexity(correct_sentence, trigram_prob,tri_context_counts, 3, vocab_size)\n",
        "\n",
        "wrong_tri_prob = calculate_sentence_prob(incorrect_sentence, trigram_prob,tri_context_counts,3, vocab_size)\n",
        "wrong_tri_perplexity = perplexity(incorrect_sentence, trigram_prob,tri_context_counts, 3, vocab_size)\n",
        "\n",
        "# print the results\n",
        "# 1-gram\n",
        "print(f\"1-gram correct sentence probability: {correct_uni_prob}, correct sentence perplexity: {correct_uni_perplexity}\")\n",
        "print(f\"1-gram incorrect sentence probability: {wrong_uni_prob}, incorrect sentence perplexity: {wrong_uni_perplexity}\")\n",
        "\n",
        "# 2-gram\n",
        "print(f\"2-gram correct sentence probability: {correct_bi_prob}, correct sentence perplexity: {correct_bi_perplexity}\")\n",
        "print(f\"2-gram incorrect sentence probability: {wrong_bi_prob}, incorrect sentence perplexity: {wrong_bi_perplexity}\")\n",
        "\n",
        "# 3-gram\n",
        "print(f\"3-gram correct sentence probability: {correct_tri_prob}, correct sentence perplexity: {correct_tri_perplexity}\")\n",
        "print(f\"3-gram incorrect sentence probability: {wrong_tri_prob}, incorrect sentence perplexity: {wrong_tri_perplexity}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtNQHPNSZDLL"
      },
      "source": [
        "### Conclusion:\n",
        "- Probability: In both 2-gram and 3-gram models, the correct sentence has a significantly higher probability than the incorrect sentence. The 1-gram model does not show this difference because it does not consider word order.\n",
        "- Perplexity: The perplexity is much higher for the incorrect sentence in both 2-gram and 3-gram models, indicates they are hard to predict due to unusual orders."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
